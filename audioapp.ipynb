{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90477795",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "from collections import Counter\n",
    "import re\n",
    "import customtkinter as ctk\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from anthropic import Anthropic\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "import queue\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "# Set appearance mode and color theme\n",
    "ctk.set_appearance_mode(\"dark\")\n",
    "ctk.set_default_color_theme(\"blue\")\n",
    "\n",
    "class AudioAnalyzerApp(ctk.CTk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.title(\"Audio Transcription & Analysis Tool\")\n",
    "        self.geometry(\"1400x800\")\n",
    "        \n",
    "        # Make window resizable with minimum size\n",
    "        self.minsize(1200, 600)\n",
    "        self.resizable(True, True)\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.audio_file_path = None\n",
    "        self.transcribed_text = \"\"\n",
    "        self.api_key = None\n",
    "        self.whisper_model = None\n",
    "        self.error_queue = queue.Queue()\n",
    "        self.model_loading = False\n",
    "        \n",
    "        # History for processed results (prompt, output) pairs\n",
    "        self.process_history: List[Tuple[str, str]] = []\n",
    "        self.current_history_index = -1\n",
    "        \n",
    "        # Recording variables\n",
    "        self.is_recording = False\n",
    "        self.recording_data = []\n",
    "        self.recording_samplerate = 44100\n",
    "        self.recording_thread = None\n",
    "        self.recording_start_time = None\n",
    "        self.recorded_file_path = None\n",
    "        self.recording_process = None\n",
    "        \n",
    "        # Time segment variables\n",
    "        self.audio_duration = None\n",
    "        self.last_transcription_segment = (None, None)\n",
    "        \n",
    "        # Network plot variables\n",
    "        self.current_network_plot_path = None\n",
    "        self.word2vec_model = None\n",
    "        self.network_photo = None  # Store the photo reference\n",
    "        \n",
    "        # Configure grid weight for resizing\n",
    "        self.grid_columnconfigure(0, weight=1)\n",
    "        self.grid_rowconfigure(0, weight=1)\n",
    "        \n",
    "        # Create main container with proper scaling\n",
    "        self.main_container = ctk.CTkFrame(self)\n",
    "        self.main_container.grid(row=0, column=0, sticky=\"nsew\", padx=10, pady=10)\n",
    "        self.main_container.grid_columnconfigure(0, weight=0)  # Sidebar doesn't resize\n",
    "        self.main_container.grid_columnconfigure(1, weight=3)  # Main content scales\n",
    "        self.main_container.grid_rowconfigure(0, weight=1)\n",
    "        \n",
    "        # Create UI components\n",
    "        self.create_sidebar()\n",
    "        self.create_main_panel()\n",
    "        \n",
    "        # Bind resize event for network plot\n",
    "        self.bind(\"<Configure>\", self.on_window_resize)\n",
    "        \n",
    "        # Start checking for errors from background threads\n",
    "        self.check_error_queue()\n",
    "        \n",
    "        # Initialize Whisper model in background\n",
    "        self.load_whisper_model()\n",
    "\n",
    "    def toggle_time_segment(self):\n",
    "        \"\"\"Toggle between full audio and time segment selection\"\"\"\n",
    "        if self.use_full_audio_var.get():\n",
    "            # Disable time inputs\n",
    "            self.start_time_entry.configure(state=\"disabled\")\n",
    "            self.end_time_entry.configure(state=\"disabled\")\n",
    "            self.duration_info_label.configure(text=\"Duration: Full audio\")\n",
    "        else:\n",
    "            # Enable time inputs\n",
    "            self.start_time_entry.configure(state=\"normal\")\n",
    "            self.end_time_entry.configure(state=\"normal\")\n",
    "            self.update_duration_info()\n",
    "        \n",
    "        # Update button states since we may need to re-transcribe\n",
    "        self.update_button_states()\n",
    "    \n",
    "    def update_duration_info(self):\n",
    "        \"\"\"Update the duration info label based on selected time segment\"\"\"\n",
    "        if self.use_full_audio_var.get():\n",
    "            self.duration_info_label.configure(text=\"Duration: Full audio\")\n",
    "        else:\n",
    "            try:\n",
    "                start = float(self.start_time_var.get() or 0)\n",
    "                end = float(self.end_time_var.get() or 0)\n",
    "                \n",
    "                if end > start:\n",
    "                    duration = end - start\n",
    "                    mins, secs = divmod(int(duration), 60)\n",
    "                    self.duration_info_label.configure(\n",
    "                        text=f\"Duration: {mins:02d}:{secs:02d} ({duration:.1f}s)\",\n",
    "                        text_color=(\"green\", \"lightgreen\")\n",
    "                    )\n",
    "                else:\n",
    "                    self.duration_info_label.configure(\n",
    "                        text=\"Invalid range: End must be after Start\",\n",
    "                        text_color=(\"red\", \"lightcoral\")\n",
    "                    )\n",
    "            except ValueError:\n",
    "                self.duration_info_label.configure(\n",
    "                    text=\"Invalid input: Enter numbers only\",\n",
    "                    text_color=(\"red\", \"lightcoral\")\n",
    "                )\n",
    "    \n",
    "    def get_audio_duration(self, file_path):\n",
    "        \"\"\"Get the duration of an audio/video file in seconds\"\"\"\n",
    "        try:\n",
    "            # Try with soundfile first\n",
    "            import soundfile as sf\n",
    "            info = sf.info(file_path)\n",
    "            return info.duration\n",
    "        except:\n",
    "            try:\n",
    "                # Try with ffmpeg as fallback\n",
    "                import subprocess\n",
    "                import json\n",
    "                \n",
    "                cmd = [\n",
    "                    'ffprobe', '-v', 'quiet',\n",
    "                    '-print_format', 'json',\n",
    "                    '-show_format',\n",
    "                    file_path\n",
    "                ]\n",
    "                \n",
    "                result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "                if result.returncode == 0:\n",
    "                    data = json.loads(result.stdout)\n",
    "                    duration = float(data['format']['duration'])\n",
    "                    return duration\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # If all methods fail, return None\n",
    "        return None\n",
    "    \n",
    "    def update_valid_range(self):\n",
    "        \"\"\"Update the valid range label based on loaded audio file\"\"\"\n",
    "        if self.audio_file_path:\n",
    "            duration = self.get_audio_duration(self.audio_file_path)\n",
    "            if duration:\n",
    "                mins, secs = divmod(int(duration), 60)\n",
    "                self.valid_range_label.configure(\n",
    "                    text=f\"Valid range: 0 - {duration:.1f}s ({mins:02d}:{secs:02d})\",\n",
    "                    text_color=(\"blue\", \"lightblue\")\n",
    "                )\n",
    "                \n",
    "                # Update end time to match duration if using full audio\n",
    "                if self.use_full_audio_var.get():\n",
    "                    self.end_time_var.set(str(int(duration)))\n",
    "                \n",
    "                # Store duration for validation\n",
    "                self.audio_duration = duration\n",
    "            else:\n",
    "                self.valid_range_label.configure(\n",
    "                    text=\"Valid range: Unable to determine\",\n",
    "                    text_color=(\"orange\", \"darkorange\")\n",
    "                )\n",
    "                self.audio_duration = None\n",
    "        else:\n",
    "            self.valid_range_label.configure(\n",
    "                text=\"Valid range: No file loaded\",\n",
    "                text_color=(\"gray50\", \"gray50\")\n",
    "            )\n",
    "            self.audio_duration = None\n",
    "    \n",
    "    def validate_time_segment(self):\n",
    "        \"\"\"Validate the selected time segment\"\"\"\n",
    "        if self.use_full_audio_var.get():\n",
    "            return True\n",
    "        \n",
    "        try:\n",
    "            start = float(self.start_time_var.get() or 0)\n",
    "            end = float(self.end_time_var.get() or 0)\n",
    "            \n",
    "            if start < 0:\n",
    "                messagebox.showwarning(\"Invalid Time\", \"Start time cannot be negative\")\n",
    "                return False\n",
    "            \n",
    "            if end <= start:\n",
    "                messagebox.showwarning(\"Invalid Time\", \"End time must be after start time\")\n",
    "                return False\n",
    "            \n",
    "            if hasattr(self, 'audio_duration') and self.audio_duration:\n",
    "                if end > self.audio_duration:\n",
    "                    messagebox.showwarning(\"Invalid Time\", f\"End time exceeds audio duration ({self.audio_duration:.1f}s)\")\n",
    "                    return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except ValueError:\n",
    "            messagebox.showwarning(\"Invalid Input\", \"Please enter valid numbers for time segment\")\n",
    "            return False\n",
    "    \n",
    "    def get_time_segment_params(self):\n",
    "        \"\"\"Get the time segment parameters for transcription\"\"\"\n",
    "        if self.use_full_audio_var.get():\n",
    "            return None, None\n",
    "        \n",
    "        try:\n",
    "            start = float(self.start_time_var.get() or 0)\n",
    "            end = float(self.end_time_var.get() or 0)\n",
    "            return start, end\n",
    "        except ValueError:\n",
    "            return None, None\n",
    "\n",
    "    def create_sidebar(self):\n",
    "        \"\"\"Updated create_sidebar method with new features integrated\"\"\"\n",
    "        # Create a scrollable sidebar container\n",
    "        sidebar_container = ctk.CTkFrame(self.main_container, width=320)\n",
    "        sidebar_container.grid(row=0, column=0, sticky=\"nsew\", padx=(0, 10))\n",
    "        sidebar_container.grid_propagate(False)\n",
    "        sidebar_container.grid_rowconfigure(0, weight=1)\n",
    "        sidebar_container.grid_columnconfigure(0, weight=1)\n",
    "        \n",
    "        # Create scrollable frame\n",
    "        self.sidebar_scroll = ctk.CTkScrollableFrame(\n",
    "            sidebar_container,\n",
    "            width=300,\n",
    "            corner_radius=0\n",
    "        )\n",
    "        self.sidebar_scroll.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        \n",
    "        # Use self.sidebar_scroll as the parent for all sidebar content\n",
    "        self.sidebar = self.sidebar_scroll  # For compatibility with existing code\n",
    "        \n",
    "        # Title\n",
    "        title_label = ctk.CTkLabel(\n",
    "            self.sidebar, \n",
    "            text=\"DeScribe.AI\", \n",
    "            font=ctk.CTkFont(size=24, weight=\"bold\")\n",
    "        )\n",
    "        title_label.pack(pady=(20, 20))\n",
    "        \n",
    "        # Step 1: File Selection Section\n",
    "        step1_frame = ctk.CTkFrame(self.sidebar, fg_color=\"transparent\")\n",
    "        step1_frame.pack(fill=\"x\", padx=20, pady=(0, 15))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            step1_frame, \n",
    "            text=\"Step 1: Select Audio File\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(anchor=\"w\", pady=(0, 10))\n",
    "        \n",
    "        self.file_button = ctk.CTkButton(\n",
    "            step1_frame,\n",
    "            text=\"📁 Choose Audio File\",\n",
    "            command=self.select_audio_file,\n",
    "            height=40\n",
    "        )\n",
    "        self.file_button.pack(fill=\"x\", pady=(0, 5))\n",
    "        \n",
    "        self.file_label = ctk.CTkLabel(\n",
    "            step1_frame, \n",
    "            text=\"No file selected\", \n",
    "            wraplength=250,\n",
    "            font=ctk.CTkFont(size=11)\n",
    "        )\n",
    "        self.file_label.pack(anchor=\"w\")\n",
    "        \n",
    "        # Recording Section (between Step 1 and Step 2)\n",
    "        recording_frame = ctk.CTkFrame(self.sidebar, fg_color=\"transparent\")\n",
    "        recording_frame.pack(fill=\"x\", padx=20, pady=(0, 15))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            recording_frame,\n",
    "            text=\"Or Record Audio:\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(anchor=\"w\", pady=(0, 10))\n",
    "        \n",
    "        # Recording controls frame\n",
    "        record_controls = ctk.CTkFrame(recording_frame)\n",
    "        record_controls.pack(fill=\"x\")\n",
    "        \n",
    "        self.record_button = ctk.CTkButton(\n",
    "            record_controls,\n",
    "            text=\"🎤 Start Recording\",\n",
    "            command=self.toggle_recording,\n",
    "            height=40,\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        )\n",
    "        self.record_button.pack(fill=\"x\", pady=(0, 5))\n",
    "        \n",
    "        # Recording status\n",
    "        self.recording_status = ctk.CTkLabel(\n",
    "            record_controls,\n",
    "            text=\"Ready to record\",\n",
    "            font=ctk.CTkFont(size=11)\n",
    "        )\n",
    "        self.recording_status.pack(anchor=\"w\", pady=(0, 5))\n",
    "        \n",
    "        # Recording timer\n",
    "        self.recording_timer = ctk.CTkLabel(\n",
    "            record_controls,\n",
    "            text=\"\",\n",
    "            font=ctk.CTkFont(size=11),\n",
    "            text_color=(\"red\", \"lightcoral\")\n",
    "        )\n",
    "        self.recording_timer.pack(anchor=\"w\")\n",
    "        \n",
    "        # Use recording button\n",
    "        self.use_recording_button = ctk.CTkButton(\n",
    "            record_controls,\n",
    "            text=\"📂 Use Recording\",\n",
    "            command=self.use_recording,\n",
    "            height=32,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.use_recording_button.pack(fill=\"x\", pady=(5, 0))\n",
    "        \n",
    "        # Time Segment Selection\n",
    "        time_segment_frame = ctk.CTkFrame(self.sidebar, fg_color=\"transparent\")\n",
    "        time_segment_frame.pack(fill=\"x\", padx=20, pady=(0, 15))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            time_segment_frame,\n",
    "            text=\"Time Segment Selection:\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(anchor=\"w\", pady=(0, 10))\n",
    "        \n",
    "        # Use full audio checkbox\n",
    "        self.use_full_audio_var = ctk.BooleanVar(value=True)\n",
    "        self.use_full_audio_check = ctk.CTkCheckBox(\n",
    "            time_segment_frame,\n",
    "            text=\"Use full audio\",\n",
    "            variable=self.use_full_audio_var,\n",
    "            command=self.toggle_time_segment,\n",
    "            font=ctk.CTkFont(size=12)\n",
    "        )\n",
    "        self.use_full_audio_check.pack(anchor=\"w\", pady=(0, 10))\n",
    "        \n",
    "        # Time range inputs\n",
    "        time_input_frame = ctk.CTkFrame(time_segment_frame)\n",
    "        time_input_frame.pack(fill=\"x\")\n",
    "        \n",
    "        # Start time\n",
    "        start_frame = ctk.CTkFrame(time_input_frame)\n",
    "        start_frame.pack(fill=\"x\", pady=(0, 5))\n",
    "        \n",
    "        ctk.CTkLabel(start_frame, text=\"Start (seconds):\", font=ctk.CTkFont(size=11)).pack(side=\"left\", padx=(0, 10))\n",
    "        self.start_time_var = ctk.StringVar(value=\"0\")\n",
    "        self.start_time_entry = ctk.CTkEntry(\n",
    "            start_frame,\n",
    "            width=80,\n",
    "            textvariable=self.start_time_var,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.start_time_entry.pack(side=\"left\")\n",
    "        \n",
    "        # End time\n",
    "        end_frame = ctk.CTkFrame(time_input_frame)\n",
    "        end_frame.pack(fill=\"x\", pady=(0, 5))\n",
    "        \n",
    "        ctk.CTkLabel(end_frame, text=\"End (seconds):\", font=ctk.CTkFont(size=11)).pack(side=\"left\", padx=(0, 10))\n",
    "        self.end_time_var = ctk.StringVar(value=\"0\")\n",
    "        self.end_time_entry = ctk.CTkEntry(\n",
    "            end_frame,\n",
    "            width=80,\n",
    "            textvariable=self.end_time_var,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.end_time_entry.pack(side=\"left\")\n",
    "        \n",
    "        # Duration info label\n",
    "        self.duration_info_label = ctk.CTkLabel(\n",
    "            time_segment_frame,\n",
    "            text=\"Duration: Full audio\",\n",
    "            font=ctk.CTkFont(size=11),\n",
    "            text_color=(\"gray50\", \"gray50\")\n",
    "        )\n",
    "        self.duration_info_label.pack(anchor=\"w\", pady=(5, 0))\n",
    "        \n",
    "        # Valid range label\n",
    "        self.valid_range_label = ctk.CTkLabel(\n",
    "            time_segment_frame,\n",
    "            text=\"Valid range: No file loaded\",\n",
    "            font=ctk.CTkFont(size=11),\n",
    "            text_color=(\"blue\", \"lightblue\")\n",
    "        )\n",
    "        self.valid_range_label.pack(anchor=\"w\", pady=(2, 0))\n",
    "        \n",
    "        # Step 2: Transcription Section\n",
    "        step2_frame = ctk.CTkFrame(self.sidebar, fg_color=\"transparent\")\n",
    "        step2_frame.pack(fill=\"x\", padx=20, pady=(0, 15))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            step2_frame,\n",
    "            text=\"Step 2: Transcribe Audio\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(anchor=\"w\", pady=(0, 10))\n",
    "        \n",
    "        # Whisper Model Selection\n",
    "        model_container = ctk.CTkFrame(step2_frame)\n",
    "        model_container.pack(fill=\"x\", pady=(0, 10))\n",
    "        \n",
    "        ctk.CTkLabel(model_container, text=\"Whisper Model:\", font=ctk.CTkFont(size=12)).pack(anchor=\"w\", pady=(5, 5))\n",
    "        \n",
    "        model_select_frame = ctk.CTkFrame(model_container)\n",
    "        model_select_frame.pack(fill=\"x\")\n",
    "        \n",
    "        self.model_var = ctk.StringVar(value=\"base\")\n",
    "        models = [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "        self.model_menu = ctk.CTkOptionMenu(\n",
    "            model_select_frame,\n",
    "            values=models,\n",
    "            variable=self.model_var,\n",
    "            command=self.on_model_change,\n",
    "            width=140\n",
    "        )\n",
    "        self.model_menu.pack(side=\"left\", pady=(0, 5))\n",
    "        \n",
    "        # Model status indicator inline\n",
    "        self.model_status = ctk.CTkLabel(\n",
    "            model_select_frame, \n",
    "            text=\"⚪ Not loaded\",\n",
    "            font=ctk.CTkFont(size=11)\n",
    "        )\n",
    "        self.model_status.pack(side=\"left\", padx=(10, 0))\n",
    "        \n",
    "        # Transcribe Button\n",
    "        self.transcribe_button = ctk.CTkButton(\n",
    "            step2_frame,\n",
    "            text=\"🎙️ Transcribe\",\n",
    "            command=self.start_transcription,\n",
    "            height=40,\n",
    "            font=ctk.CTkFont(size=13, weight=\"bold\"),\n",
    "            state=\"disabled\",\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        )\n",
    "        self.transcribe_button.pack(fill=\"x\", pady=(5, 0))\n",
    "        \n",
    "        # Clean Text Button\n",
    "        self.clean_button = ctk.CTkButton(\n",
    "            step2_frame,\n",
    "            text=\"🧹 Clean Text\",\n",
    "            command=self.clean_transcribed_text,\n",
    "            height=35,\n",
    "            state=\"disabled\",\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        )\n",
    "        self.clean_button.pack(fill=\"x\", pady=(5, 0))\n",
    "        \n",
    "        # Network Plot Button\n",
    "        self.network_button = ctk.CTkButton(\n",
    "            step2_frame,\n",
    "            text=\"🕸️ Generate Network Plot\",\n",
    "            command=self.create_network_plot,\n",
    "            height=35,\n",
    "            state=\"disabled\",\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        )\n",
    "        self.network_button.pack(fill=\"x\", pady=(5, 0))\n",
    "        \n",
    "        # Step 3: Processing Section\n",
    "        step3_frame = ctk.CTkFrame(self.sidebar, fg_color=\"transparent\")\n",
    "        step3_frame.pack(fill=\"x\", padx=20, pady=(0, 15))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            step3_frame,\n",
    "            text=\"Step 3: Process with AI\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(anchor=\"w\", pady=(0, 10))\n",
    "        \n",
    "        # API Key Entry\n",
    "        api_container = ctk.CTkFrame(step3_frame)\n",
    "        api_container.pack(fill=\"x\", pady=(0, 10))\n",
    "        \n",
    "        ctk.CTkLabel(api_container, text=\"Anthropic API Key:\", font=ctk.CTkFont(size=12)).pack(anchor=\"w\", pady=(5, 5))\n",
    "        \n",
    "        api_entry_frame = ctk.CTkFrame(api_container)\n",
    "        api_entry_frame.pack(fill=\"x\")\n",
    "        \n",
    "        self.api_key_entry = ctk.CTkEntry(api_entry_frame, show=\"*\", width=180)\n",
    "        self.api_key_entry.pack(side=\"left\", pady=(0, 5))\n",
    "        \n",
    "        self.save_api_button = ctk.CTkButton(\n",
    "            api_entry_frame,\n",
    "            text=\"Save\",\n",
    "            command=self.save_api_key,\n",
    "            width=60,\n",
    "            height=28\n",
    "        )\n",
    "        self.save_api_button.pack(side=\"left\", padx=(5, 0))\n",
    "        \n",
    "        # Create the new summarize section with templates and tones\n",
    "        self.create_summarize_section(step3_frame)\n",
    "        \n",
    "        # Create the translation section\n",
    "        self.create_translation_section(self.sidebar)\n",
    "        \n",
    "        # Output Format\n",
    "        format_frame = ctk.CTkFrame(step3_frame)\n",
    "        format_frame.pack(fill=\"x\", pady=(10, 0))\n",
    "        \n",
    "        ctk.CTkLabel(format_frame, text=\"Output Format:\", font=ctk.CTkFont(size=11)).pack(side=\"left\", padx=(0, 10))\n",
    "        \n",
    "        self.output_format = ctk.StringVar(value=\"Markdown\")\n",
    "        formats = [\"Markdown\", \"Plain Text\", \"JSON\", \"Bullet Points\", \"LaTeX PDF\"]\n",
    "        self.format_menu = ctk.CTkOptionMenu(\n",
    "            format_frame,\n",
    "            values=formats,\n",
    "            variable=self.output_format,\n",
    "            width=140,\n",
    "            height=28\n",
    "        )\n",
    "        self.format_menu.pack(side=\"left\", fill=\"x\", expand=True)\n",
    "        \n",
    "        # Progress Section\n",
    "        progress_frame = ctk.CTkFrame(self.sidebar, fg_color=\"transparent\")\n",
    "        progress_frame.pack(fill=\"x\", padx=20, pady=(20, 20))\n",
    "        \n",
    "        self.progress_bar = ctk.CTkProgressBar(progress_frame)\n",
    "        self.progress_bar.pack(fill=\"x\", pady=(0, 5))\n",
    "        self.progress_bar.set(0)\n",
    "        \n",
    "        self.status_label = ctk.CTkLabel(\n",
    "            progress_frame, \n",
    "            text=\"Ready\", \n",
    "            font=ctk.CTkFont(size=11)\n",
    "        )\n",
    "        self.status_label.pack()\n",
    "\n",
    "    def create_summarize_section(self, parent_frame):\n",
    "        \"\"\"Create the summarize section with templates and tones\"\"\"\n",
    "        # Summarize Options\n",
    "        summarize_frame = ctk.CTkFrame(parent_frame)\n",
    "        summarize_frame.pack(fill=\"x\", pady=(10, 0))\n",
    "        \n",
    "        # Template selection\n",
    "        template_frame = ctk.CTkFrame(summarize_frame)\n",
    "        template_frame.pack(fill=\"x\", pady=(0, 10))\n",
    "        \n",
    "        ctk.CTkLabel(template_frame, text=\"Template:\", font=ctk.CTkFont(size=12)).pack(side=\"left\", padx=(0, 10))\n",
    "        \n",
    "        self.summary_template_var = ctk.StringVar(value=\"Standard\")\n",
    "        templates = [\n",
    "            \"Standard\",\n",
    "            \"Executive Summary\",\n",
    "            \"Academic Paper\",\n",
    "            \"Meeting Minutes\",\n",
    "            \"Podcast Notes\",\n",
    "            \"Lecture Notes\",\n",
    "            \"Interview Summary\",\n",
    "            \"Technical Report\",\n",
    "            \"News Article\",\n",
    "            \"Research Brief\"\n",
    "        ]\n",
    "        self.template_menu = ctk.CTkOptionMenu(\n",
    "            template_frame,\n",
    "            values=templates,\n",
    "            variable=self.summary_template_var,\n",
    "            width=140,\n",
    "            height=28\n",
    "        )\n",
    "        self.template_menu.pack(side=\"left\", fill=\"x\", expand=True)\n",
    "        \n",
    "        # Tone selection\n",
    "        tone_frame = ctk.CTkFrame(summarize_frame)\n",
    "        tone_frame.pack(fill=\"x\", pady=(0, 10))\n",
    "        \n",
    "        ctk.CTkLabel(tone_frame, text=\"Tone:\", font=ctk.CTkFont(size=12)).pack(side=\"left\", padx=(0, 10))\n",
    "        \n",
    "        self.summary_tone_var = ctk.StringVar(value=\"Professional\")\n",
    "        tones = [\n",
    "            \"Professional\",\n",
    "            \"Casual\",\n",
    "            \"Academic\",\n",
    "            \"Technical\",\n",
    "            \"Creative\",\n",
    "            \"Formal\",\n",
    "            \"Conversational\",\n",
    "            \"Analytical\",\n",
    "            \"Persuasive\",\n",
    "            \"Objective\"\n",
    "        ]\n",
    "        self.tone_menu = ctk.CTkOptionMenu(\n",
    "            tone_frame,\n",
    "            values=tones,\n",
    "            variable=self.summary_tone_var,\n",
    "            width=140,\n",
    "            height=28\n",
    "        )\n",
    "        self.tone_menu.pack(side=\"left\", fill=\"x\", expand=True)\n",
    "        \n",
    "        # Word limit setting\n",
    "        word_limit_frame = ctk.CTkFrame(summarize_frame)\n",
    "        word_limit_frame.pack(fill=\"x\", pady=(0, 10))\n",
    "        \n",
    "        ctk.CTkLabel(word_limit_frame, text=\"Word Limit:\", font=ctk.CTkFont(size=12)).pack(side=\"left\", padx=(0, 10))\n",
    "        \n",
    "        self.word_limit_var = ctk.StringVar(value=\"500\")\n",
    "        self.word_limit_entry = ctk.CTkEntry(\n",
    "            word_limit_frame,\n",
    "            width=80,\n",
    "            textvariable=self.word_limit_var,\n",
    "            placeholder_text=\"500\"\n",
    "        )\n",
    "        self.word_limit_entry.pack(side=\"left\")\n",
    "        \n",
    "        ctk.CTkLabel(word_limit_frame, text=\"words\", font=ctk.CTkFont(size=11)).pack(side=\"left\", padx=(5, 0))\n",
    "        \n",
    "        # Summarize Button\n",
    "        self.summarize_button = ctk.CTkButton(\n",
    "            summarize_frame,\n",
    "            text=\"📝 Summarize\",\n",
    "            command=self.summarize_transcription,\n",
    "            height=40,\n",
    "            state=\"disabled\",\n",
    "            font=ctk.CTkFont(size=13, weight=\"bold\"),\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        )\n",
    "        self.summarize_button.pack(fill=\"x\", pady=(5, 0))\n",
    "        \n",
    "        return summarize_frame\n",
    "\n",
    "    def create_translation_section(self, parent_frame):\n",
    "        \"\"\"Create the translation section in the sidebar\"\"\"\n",
    "        # Translation Section (add after Summarize section)\n",
    "        translation_frame = ctk.CTkFrame(parent_frame, fg_color=\"transparent\")\n",
    "        translation_frame.pack(fill=\"x\", padx=20, pady=(15, 0))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            translation_frame,\n",
    "            text=\"Translation\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(anchor=\"w\", pady=(0, 10))\n",
    "        \n",
    "        # Language selection\n",
    "        lang_select_frame = ctk.CTkFrame(translation_frame)\n",
    "        lang_select_frame.pack(fill=\"x\", pady=(0, 10))\n",
    "        \n",
    "        ctk.CTkLabel(lang_select_frame, text=\"Target Language:\", font=ctk.CTkFont(size=12)).pack(anchor=\"w\", pady=(0, 5))\n",
    "        \n",
    "        self.target_language_var = ctk.StringVar(value=\"Spanish\")\n",
    "        languages = [\n",
    "            \"Spanish\", \"French\", \"German\", \"Italian\", \"Portuguese\", \"Dutch\",\n",
    "            \"Russian\", \"Chinese (Simplified)\", \"Chinese (Traditional)\", \n",
    "            \"Japanese\", \"Korean\", \"Arabic\", \"Hindi\", \"Bengali\",\n",
    "            \"Turkish\", \"Polish\", \"Vietnamese\", \"Thai\", \"Indonesian\",\n",
    "            \"Swedish\", \"Norwegian\", \"Danish\", \"Finnish\", \"Greek\",\n",
    "            \"Hebrew\", \"Czech\", \"Hungarian\", \"Romanian\", \"Ukrainian\"\n",
    "        ]\n",
    "        self.language_menu = ctk.CTkOptionMenu(\n",
    "            lang_select_frame,\n",
    "            values=languages,\n",
    "            variable=self.target_language_var,\n",
    "            width=180,\n",
    "            height=32\n",
    "        )\n",
    "        self.language_menu.pack(fill=\"x\")\n",
    "        \n",
    "        # Translation style options\n",
    "        style_frame = ctk.CTkFrame(translation_frame)\n",
    "        style_frame.pack(fill=\"x\", pady=(0, 10))\n",
    "        \n",
    "        ctk.CTkLabel(style_frame, text=\"Translation Style:\", font=ctk.CTkFont(size=12)).pack(anchor=\"w\", pady=(0, 5))\n",
    "        \n",
    "        self.translation_style_var = ctk.StringVar(value=\"Natural\")\n",
    "        styles = [\"Natural\", \"Literal\", \"Professional\", \"Colloquial\", \"Technical\"]\n",
    "        self.style_menu = ctk.CTkOptionMenu(\n",
    "            style_frame,\n",
    "            values=styles,\n",
    "            variable=self.translation_style_var,\n",
    "            width=180,\n",
    "            height=28\n",
    "        )\n",
    "        self.style_menu.pack(fill=\"x\")\n",
    "        \n",
    "        # Preserve formatting checkbox\n",
    "        self.preserve_formatting_var = ctk.BooleanVar(value=True)\n",
    "        self.preserve_formatting_check = ctk.CTkCheckBox(\n",
    "            translation_frame,\n",
    "            text=\"Preserve original formatting\",\n",
    "            variable=self.preserve_formatting_var,\n",
    "            font=ctk.CTkFont(size=12)\n",
    "        )\n",
    "        self.preserve_formatting_check.pack(anchor=\"w\", pady=(5, 10))\n",
    "        \n",
    "        # Translate button\n",
    "        self.translate_button = ctk.CTkButton(\n",
    "            translation_frame,\n",
    "            text=\"🌐 Translate\",\n",
    "            command=self.translate_transcription,\n",
    "            height=40,\n",
    "            state=\"disabled\",\n",
    "            font=ctk.CTkFont(size=13, weight=\"bold\"),\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        )\n",
    "        self.translate_button.pack(fill=\"x\")\n",
    "        \n",
    "        return translation_frame\n",
    "    \n",
    "    def translate_transcription(self):\n",
    "        \"\"\"Translate the transcribed text to the selected language\"\"\"\n",
    "        if not self.transcribed_text:\n",
    "            messagebox.showwarning(\"No Content\", \"No transcription available to translate\")\n",
    "            return\n",
    "        \n",
    "        api_key = self.api_key_entry.get() or self.api_key\n",
    "        if not api_key:\n",
    "            messagebox.showwarning(\"API Key Required\", \"Please enter your Anthropic API key\")\n",
    "            return\n",
    "        \n",
    "        target_language = self.target_language_var.get()\n",
    "        translation_style = self.translation_style_var.get()\n",
    "        preserve_formatting = self.preserve_formatting_var.get()\n",
    "        \n",
    "        def translate():\n",
    "            try:\n",
    "                self.after(0, lambda: self.translate_button.configure(state=\"disabled\"))\n",
    "                self.after(0, lambda: self.update_status(f\"Translating to {target_language}...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.5))\n",
    "                \n",
    "                prompt = self.get_translation_prompt(\n",
    "                    self.transcribed_text,\n",
    "                    target_language,\n",
    "                    translation_style,\n",
    "                    preserve_formatting\n",
    "                )\n",
    "                \n",
    "                result = self.process_with_claude_enhanced(self.transcribed_text, prompt)\n",
    "                \n",
    "                if result:\n",
    "                    # Update the result with language info\n",
    "                    result_with_header = f\"[Translation to {target_language}]\\n\\n{result}\"\n",
    "                    self.after(0, lambda: self.update_result(prompt, result_with_header))\n",
    "                    self.after(0, lambda: self.update_status(f\"Translation to {target_language} completed\"))\n",
    "                else:\n",
    "                    self.after(0, lambda: self.update_status(\"Translation failed\"))\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Translation Error\", f\"Failed to translate: {str(e)}\"))\n",
    "            finally:\n",
    "                self.after(0, lambda: self.progress_bar.set(0))\n",
    "                self.after(0, lambda: self.translate_button.configure(state=\"normal\"))\n",
    "        \n",
    "        threading.Thread(target=translate, daemon=True).start()\n",
    "    \n",
    "    def get_translation_prompt(self, text: str, target_language: str, style: str, preserve_formatting: bool) -> str:\n",
    "        \"\"\"Generate translation prompt based on settings\"\"\"\n",
    "        output_format = self.output_format.get()\n",
    "        \n",
    "        # Style-specific instructions\n",
    "        style_instructions = {\n",
    "            \"Natural\": \"Translate in a natural, fluent way that sounds native to the target language.\",\n",
    "            \"Literal\": \"Provide a more literal translation that stays close to the original structure.\",\n",
    "            \"Professional\": \"Use formal, professional language suitable for business or academic contexts.\",\n",
    "            \"Colloquial\": \"Use everyday, conversational language with appropriate idioms.\",\n",
    "            \"Technical\": \"Maintain technical terminology and precision, transliterating terms when necessary.\"\n",
    "        }\n",
    "        \n",
    "        # Format-specific instructions for different languages\n",
    "        format_instructions = {\n",
    "            \"markdown\": \"Maintain Markdown formatting. Translate headers, lists, and content while preserving structure.\",\n",
    "            \"plain text\": \"Provide plain text translation without special formatting.\",\n",
    "            \"json\": f\"Return as JSON with structure: {{\\\"language\\\": \\\"{target_language}\\\", \\\"translation\\\": \\\"...\\\", \\\"notes\\\": \\\"...\\\"}}\",\n",
    "            \"bullet points\": \"Maintain bullet point structure while translating content.\",\n",
    "            \"latex pdf\": \"Preserve LaTeX commands and structure. Translate content while keeping LaTeX formatting intact. Use appropriate language packages if needed (e.g., \\\\usepackage[arabic]{babel} for Arabic).\"\n",
    "        }\n",
    "        \n",
    "        # Special handling for certain languages\n",
    "        special_instructions = \"\"\n",
    "        if target_language in [\"Arabic\", \"Hebrew\"]:\n",
    "            special_instructions = \"\\nNote: This language uses right-to-left script. Ensure proper text direction in the output.\"\n",
    "        elif target_language in [\"Chinese (Simplified)\", \"Chinese (Traditional)\", \"Japanese\", \"Korean\"]:\n",
    "            special_instructions = \"\\nNote: Handle character encoding carefully for East Asian languages.\"\n",
    "        \n",
    "        prompt = f\"\"\"Translate the following transcribed text to {target_language}.\n",
    "    \n",
    "    TRANSLATION STYLE: {style}\n",
    "    {style_instructions.get(style, '')}\n",
    "    \n",
    "    OUTPUT FORMAT: {output_format}\n",
    "    {format_instructions.get(output_format.lower(), '')}\n",
    "    \n",
    "    {\"PRESERVE ORIGINAL FORMATTING: Maintain paragraph breaks, punctuation style, and structure.\" if preserve_formatting else \"ADAPT FORMATTING: Adjust formatting to be natural for the target language.\"}\n",
    "    {special_instructions}\n",
    "    \n",
    "    Important instructions:\n",
    "    1. Translate all content accurately while maintaining the original meaning\n",
    "    2. Adapt idioms and expressions to be culturally appropriate\n",
    "    3. For technical terms without direct translations, provide the translation followed by the original term in parentheses\n",
    "    4. Ensure grammatical correctness in the target language\n",
    "    5. If the output format is LaTeX, include appropriate language packages in the preamble\n",
    "    \n",
    "    Text to translate:\n",
    "    {text}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def ensure_latex_format_multilingual(self, text: str, language: str) -> str:\n",
    "        \"\"\"Ensure LaTeX format works with multiple languages\"\"\"\n",
    "        \n",
    "        # Language-specific LaTeX packages\n",
    "        language_packages = {\n",
    "            \"Arabic\": \"\\\\usepackage[arabic]{babel}\\n\\\\usepackage{arabtex}\",\n",
    "            \"Chinese (Simplified)\": \"\\\\usepackage{CJKutf8}\",\n",
    "            \"Chinese (Traditional)\": \"\\\\usepackage{CJKutf8}\",\n",
    "            \"Japanese\": \"\\\\usepackage{CJKutf8}\",\n",
    "            \"Korean\": \"\\\\usepackage{CJKutf8}\",\n",
    "            \"Russian\": \"\\\\usepackage[russian]{babel}\",\n",
    "            \"Greek\": \"\\\\usepackage[greek]{babel}\",\n",
    "            \"Hebrew\": \"\\\\usepackage[hebrew]{babel}\"\n",
    "        }\n",
    "        \n",
    "        # First ensure basic LaTeX format\n",
    "        text = self.ensure_latex_format(text)\n",
    "        \n",
    "        # Add language-specific packages if needed\n",
    "        if language in language_packages:\n",
    "            lines = text.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.startswith(\"\\\\documentclass\"):\n",
    "                    # Insert language package after documentclass\n",
    "                    package = language_packages[language]\n",
    "                    lines.insert(i + 1, package)\n",
    "                    break\n",
    "            text = '\\n'.join(lines)\n",
    "        \n",
    "        # Special handling for CJK languages\n",
    "        if language in [\"Chinese (Simplified)\", \"Chinese (Traditional)\", \"Japanese\", \"Korean\"]:\n",
    "            # Wrap content in CJK environment\n",
    "            if \"\\\\begin{document}\" in text and \"\\\\end{document}\" in text:\n",
    "                start = text.index(\"\\\\begin{document}\") + len(\"\\\\begin{document}\")\n",
    "                end = text.index(\"\\\\end{document}\")\n",
    "                content = text[start:end]\n",
    "                \n",
    "                cjk_env = \"CJK*{UTF8}{gbsn}\" if \"Chinese\" in language else \"CJK*{UTF8}{min}\"\n",
    "                wrapped_content = f\"\\n\\\\begin{{{cjk_env}}}\\n{content}\\n\\\\end{{CJK*}}\\n\"\n",
    "                \n",
    "                text = text[:start] + wrapped_content + text[end:]\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def create_main_panel(self):\n",
    "        \"\"\"Create main panel with three columns: left sidebar, center content, right visualization\"\"\"\n",
    "        # Main Panel Container\n",
    "        self.main_panel = ctk.CTkFrame(self.main_container)\n",
    "        self.main_panel.grid(row=0, column=1, sticky=\"nsew\")\n",
    "        self.main_panel.grid_columnconfigure(0, weight=3)  # Center panel gets more weight\n",
    "        self.main_panel.grid_columnconfigure(1, weight=2)  # Right panel for visualization\n",
    "        self.main_panel.grid_rowconfigure(0, weight=1)\n",
    "        \n",
    "        # LEFT/CENTER: Original tabbed content\n",
    "        self.center_container = ctk.CTkFrame(self.main_panel)\n",
    "        self.center_container.grid(row=0, column=0, sticky=\"nsew\", padx=(0, 5))\n",
    "        self.center_container.grid_columnconfigure(0, weight=1)\n",
    "        self.center_container.grid_rowconfigure(0, weight=1)\n",
    "        self.center_container.grid_rowconfigure(1, weight=0)\n",
    "        \n",
    "        # Tab View (in center)\n",
    "        self.tabview = ctk.CTkTabview(self.center_container)\n",
    "        self.tabview.grid(row=0, column=0, sticky=\"nsew\", padx=10, pady=10)\n",
    "        \n",
    "        # Transcription Tab\n",
    "        self.trans_tab = self.tabview.add(\"📝 Transcription\")\n",
    "        trans_frame = ctk.CTkFrame(self.trans_tab)\n",
    "        trans_frame.pack(fill=\"both\", expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # Transcription header with word count\n",
    "        trans_header = ctk.CTkFrame(trans_frame, height=30)\n",
    "        trans_header.pack(fill=\"x\", pady=(0, 5))\n",
    "        \n",
    "        self.trans_word_count = ctk.CTkLabel(\n",
    "            trans_header, \n",
    "            text=\"Words: 0 | Characters: 0\",\n",
    "            font=ctk.CTkFont(size=11)\n",
    "        )\n",
    "        self.trans_word_count.pack(side=\"left\")\n",
    "        \n",
    "        self.trans_status = ctk.CTkLabel(\n",
    "            trans_header,\n",
    "            text=\"No transcription yet\",\n",
    "            font=ctk.CTkFont(size=11),\n",
    "            text_color=(\"gray50\", \"gray50\")\n",
    "        )\n",
    "        self.trans_status.pack(side=\"right\")\n",
    "        \n",
    "        self.trans_text = ctk.CTkTextbox(\n",
    "            trans_frame,\n",
    "            font=ctk.CTkFont(size=13),\n",
    "            wrap=\"word\"\n",
    "        )\n",
    "        self.trans_text.pack(fill=\"both\", expand=True)\n",
    "        \n",
    "        # Processed Result Tab - Split view\n",
    "        self.result_tab = self.tabview.add(\"✨ Processed Result\")\n",
    "        result_container = ctk.CTkFrame(self.result_tab)\n",
    "        result_container.pack(fill=\"both\", expand=True, padx=5, pady=5)\n",
    "        result_container.grid_columnconfigure(0, weight=1)\n",
    "        result_container.grid_rowconfigure(0, weight=2)\n",
    "        result_container.grid_rowconfigure(1, weight=1)\n",
    "        \n",
    "        # Upper section - API output\n",
    "        upper_frame = ctk.CTkFrame(result_container)\n",
    "        upper_frame.grid(row=0, column=0, sticky=\"nsew\", pady=(0, 5))\n",
    "        \n",
    "        # Result header with navigation\n",
    "        result_header = ctk.CTkFrame(upper_frame, height=30)\n",
    "        result_header.pack(fill=\"x\", pady=(0, 5))\n",
    "        \n",
    "        # Navigation buttons for history\n",
    "        nav_frame = ctk.CTkFrame(result_header)\n",
    "        nav_frame.pack(side=\"left\")\n",
    "        \n",
    "        self.prev_button = ctk.CTkButton(\n",
    "            nav_frame,\n",
    "            text=\"◀\",\n",
    "            width=30,\n",
    "            height=25,\n",
    "            command=self.navigate_history_prev,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.prev_button.pack(side=\"left\", padx=2)\n",
    "        \n",
    "        self.history_label = ctk.CTkLabel(\n",
    "            nav_frame,\n",
    "            text=\"0/0\",\n",
    "            font=ctk.CTkFont(size=11),\n",
    "            width=50\n",
    "        )\n",
    "        self.history_label.pack(side=\"left\", padx=5)\n",
    "        \n",
    "        self.next_button = ctk.CTkButton(\n",
    "            nav_frame,\n",
    "            text=\"▶\",\n",
    "            width=30,\n",
    "            height=25,\n",
    "            command=self.navigate_history_next,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.next_button.pack(side=\"left\", padx=2)\n",
    "        \n",
    "        self.result_status = ctk.CTkLabel(\n",
    "            result_header,\n",
    "            text=\"No processed result yet\",\n",
    "            font=ctk.CTkFont(size=11),\n",
    "            text_color=(\"gray50\", \"gray50\")\n",
    "        )\n",
    "        self.result_status.pack(side=\"right\")\n",
    "        \n",
    "        self.result_text = ctk.CTkTextbox(\n",
    "            upper_frame,\n",
    "            font=ctk.CTkFont(size=13),\n",
    "            wrap=\"word\"\n",
    "        )\n",
    "        self.result_text.pack(fill=\"both\", expand=True)\n",
    "        \n",
    "        # Lower section - Custom prompt\n",
    "        lower_frame = ctk.CTkFrame(result_container)\n",
    "        lower_frame.grid(row=1, column=0, sticky=\"nsew\", pady=(5, 0))\n",
    "        \n",
    "        # Custom prompt header\n",
    "        prompt_header = ctk.CTkFrame(lower_frame)\n",
    "        prompt_header.pack(fill=\"x\", pady=(5, 5))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            prompt_header,\n",
    "            text=\"Custom Prompt (use {text} for transcription):\",\n",
    "            font=ctk.CTkFont(size=12)\n",
    "        ).pack(side=\"left\")\n",
    "        \n",
    "        # Custom prompt input\n",
    "        prompt_input_frame = ctk.CTkFrame(lower_frame)\n",
    "        prompt_input_frame.pack(fill=\"both\", expand=True, pady=(0, 5))\n",
    "        \n",
    "        self.custom_prompt_text = ctk.CTkTextbox(\n",
    "            prompt_input_frame,\n",
    "            height=100,\n",
    "            font=ctk.CTkFont(size=12)\n",
    "        )\n",
    "        self.custom_prompt_text.pack(fill=\"both\", expand=True, pady=(0, 5))\n",
    "        self.custom_prompt_text.insert(\"1.0\", \"Analyze the following text and provide insights:\\n\\n{text}\")\n",
    "        \n",
    "        # Process custom prompt button\n",
    "        self.process_custom_button = ctk.CTkButton(\n",
    "            prompt_input_frame,\n",
    "            text=\"▶ Process Custom Prompt\",\n",
    "            command=self.process_custom_prompt,\n",
    "            height=32,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.process_custom_button.pack(fill=\"x\")\n",
    "        \n",
    "        # Bottom toolbar (for center panel)\n",
    "        toolbar_frame = ctk.CTkFrame(self.center_container)\n",
    "        toolbar_frame.grid(row=1, column=0, sticky=\"ew\", padx=10, pady=(0, 10))\n",
    "        \n",
    "        # Left side buttons\n",
    "        left_buttons = ctk.CTkFrame(toolbar_frame)\n",
    "        left_buttons.pack(side=\"left\")\n",
    "        \n",
    "        ctk.CTkButton(\n",
    "            left_buttons,\n",
    "            text=\"📋 Copy Current Tab\",\n",
    "            command=self.copy_to_clipboard,\n",
    "            width=130,\n",
    "            height=32\n",
    "        ).pack(side=\"left\", padx=2)\n",
    "        \n",
    "        ctk.CTkButton(\n",
    "            left_buttons,\n",
    "            text=\"💾 Export Transcription\",\n",
    "            command=lambda: self.export_text_enhanced(\"transcription\"),\n",
    "            width=140,\n",
    "            height=32\n",
    "        ).pack(side=\"left\", padx=2)\n",
    "        \n",
    "        ctk.CTkButton(\n",
    "            left_buttons,\n",
    "            text=\"💾 Export Result\",\n",
    "            command=lambda: self.export_text_enhanced(\"result\"),\n",
    "            width=120,\n",
    "            height=32\n",
    "        ).pack(side=\"left\", padx=2)\n",
    "        \n",
    "        # Right side buttons\n",
    "        ctk.CTkButton(\n",
    "            toolbar_frame,\n",
    "            text=\"🗑️ Clear All\",\n",
    "            command=self.clear_all,\n",
    "            width=100,\n",
    "            height=32,\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        ).pack(side=\"right\", padx=2)\n",
    "        \n",
    "        # RIGHT: Visualization Panel with proper scaling\n",
    "        self.viz_panel = ctk.CTkFrame(self.main_panel)\n",
    "        self.viz_panel.grid(row=0, column=1, sticky=\"nsew\", padx=(5, 0))\n",
    "        self.viz_panel.grid_columnconfigure(0, weight=1)\n",
    "        self.viz_panel.grid_rowconfigure(0, weight=2)  # Network plot gets 2/3\n",
    "        self.viz_panel.grid_rowconfigure(1, weight=1)  # Semantic summary gets 1/3\n",
    "        \n",
    "        # Upper 2/3: Network Plot Display\n",
    "        self.network_frame = ctk.CTkFrame(self.viz_panel)\n",
    "        self.network_frame.grid(row=0, column=0, sticky=\"nsew\", padx=5, pady=(5, 2))\n",
    "        self.network_frame.grid_columnconfigure(0, weight=1)\n",
    "        self.network_frame.grid_rowconfigure(1, weight=1)  # Make display area expandable\n",
    "        \n",
    "        # Network plot header\n",
    "        network_header = ctk.CTkFrame(self.network_frame, height=30)\n",
    "        network_header.grid(row=0, column=0, sticky=\"ew\", pady=(5, 5))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            network_header,\n",
    "            text=\"🕸️ Semantic Network\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(side=\"left\", padx=10)\n",
    "        \n",
    "        # Refresh button for network\n",
    "        self.refresh_network_btn = ctk.CTkButton(\n",
    "            network_header,\n",
    "            text=\"↻ Regenerate\",\n",
    "            width=100,\n",
    "            height=28,\n",
    "            command=self.create_network_plot,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.refresh_network_btn.pack(side=\"right\", padx=10)\n",
    "        \n",
    "        # Network plot display area - make it expandable\n",
    "        self.network_display = ctk.CTkLabel(\n",
    "            self.network_frame,\n",
    "            text=\"No network generated yet\\n\\nClick 'Generate Network Plot' to visualize\",\n",
    "            font=ctk.CTkFont(size=12),\n",
    "            text_color=(\"gray50\", \"gray50\")\n",
    "        )\n",
    "        self.network_display.grid(row=1, column=0, sticky=\"nsew\", padx=10, pady=10)\n",
    "        \n",
    "        # Lower 1/3: Semantic Summary\n",
    "        summary_frame = ctk.CTkFrame(self.viz_panel)\n",
    "        summary_frame.grid(row=1, column=0, sticky=\"nsew\", padx=5, pady=(2, 5))\n",
    "        \n",
    "        # Summary header\n",
    "        summary_header = ctk.CTkFrame(summary_frame, height=30)\n",
    "        summary_header.pack(fill=\"x\", pady=(5, 5))\n",
    "        \n",
    "        ctk.CTkLabel(\n",
    "            summary_header,\n",
    "            text=\"📊 Semantic & Tone Summary\",\n",
    "            font=ctk.CTkFont(size=14, weight=\"bold\")\n",
    "        ).pack(side=\"left\", padx=10)\n",
    "        \n",
    "        # Generate summary button\n",
    "        self.generate_summary_btn = ctk.CTkButton(\n",
    "            summary_header,\n",
    "            text=\"✨ Generate\",\n",
    "            width=100,\n",
    "            height=28,\n",
    "            command=self.generate_semantic_summary,\n",
    "            state=\"disabled\"\n",
    "        )\n",
    "        self.generate_summary_btn.pack(side=\"right\", padx=10)\n",
    "        \n",
    "        # Summary display\n",
    "        self.semantic_summary_text = ctk.CTkTextbox(\n",
    "            summary_frame,\n",
    "            font=ctk.CTkFont(size=12),\n",
    "            wrap=\"word\",\n",
    "            height=100\n",
    "        )\n",
    "        self.semantic_summary_text.pack(fill=\"both\", expand=True, padx=10, pady=(0, 10))\n",
    "        self.semantic_summary_text.insert(\"1.0\", \"No summary generated yet.\\n\\nClick 'Generate' to create a semantic & tone summary of the transcribed text.\")\n",
    "        self.semantic_summary_text.configure(state=\"disabled\")\n",
    "\n",
    "    def on_window_resize(self, event=None):\n",
    "        \"\"\"Handle window resize events to update network plot display\"\"\"\n",
    "        # Only process resize events for the main window\n",
    "        if event and event.widget != self:\n",
    "            return\n",
    "        \n",
    "        # Check if we have a network plot to resize\n",
    "        if hasattr(self, 'current_network_plot_path') and self.current_network_plot_path:\n",
    "            if Path(self.current_network_plot_path).exists():\n",
    "                # Delay the resize to avoid too many updates\n",
    "                if hasattr(self, '_resize_after_id'):\n",
    "                    self.after_cancel(self._resize_after_id)\n",
    "                \n",
    "                # Schedule resize after 100ms of no activity\n",
    "                self._resize_after_id = self.after(100, lambda: self.resize_network_plot())\n",
    "    \n",
    "    def resize_network_plot(self):\n",
    "        \"\"\"Resize the network plot to fit the current panel size\"\"\"\n",
    "        if not self.current_network_plot_path or not Path(self.current_network_plot_path).exists():\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            from PIL import Image, ImageTk\n",
    "            \n",
    "            # Get the current size of the network display area\n",
    "            display_width = self.network_display.winfo_width()\n",
    "            display_height = self.network_display.winfo_height()\n",
    "            \n",
    "            # Ensure minimum size\n",
    "            if display_width < 100 or display_height < 100:\n",
    "                return\n",
    "            \n",
    "            # Load the original image\n",
    "            img = Image.open(self.current_network_plot_path)\n",
    "            \n",
    "            # Calculate scaling to maintain aspect ratio with padding\n",
    "            padding = 20\n",
    "            max_width = display_width - padding\n",
    "            max_height = display_height - padding\n",
    "            \n",
    "            img_width, img_height = img.size\n",
    "            scale = min(max_width/img_width, max_height/img_height)\n",
    "            \n",
    "            # Limit maximum scale to avoid pixelation\n",
    "            scale = min(scale, 2.0)\n",
    "            \n",
    "            new_width = int(img_width * scale)\n",
    "            new_height = int(img_height * scale)\n",
    "            \n",
    "            # Resize image with high quality\n",
    "            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Convert to PhotoImage\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            \n",
    "            # Update the display\n",
    "            self.network_display.configure(image=photo, text=\"\")\n",
    "            self.network_display.image = photo  # Keep a reference\n",
    "            self.network_photo = photo  # Store reference\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error resizing network plot: {e}\")\n",
    "    \n",
    "    def navigate_history_prev(self):\n",
    "        \"\"\"Navigate to previous result in history\"\"\"\n",
    "        if self.current_history_index > 0:\n",
    "            self.current_history_index -= 1\n",
    "            self.display_history_item()\n",
    "    \n",
    "    def navigate_history_next(self):\n",
    "        \"\"\"Navigate to next result in history\"\"\"\n",
    "        if self.current_history_index < len(self.process_history) - 1:\n",
    "            self.current_history_index += 1\n",
    "            self.display_history_item()\n",
    "    \n",
    "    def display_history_item(self):\n",
    "        \"\"\"Display the current history item\"\"\"\n",
    "        if 0 <= self.current_history_index < len(self.process_history):\n",
    "            prompt, result = self.process_history[self.current_history_index]\n",
    "            \n",
    "            # Update result text\n",
    "            self.result_text.delete(\"1.0\", \"end\")\n",
    "            self.result_text.insert(\"1.0\", result)\n",
    "            \n",
    "            # Update custom prompt text\n",
    "            self.custom_prompt_text.delete(\"1.0\", \"end\")\n",
    "            self.custom_prompt_text.insert(\"1.0\", prompt)\n",
    "            \n",
    "            # Update navigation\n",
    "            self.update_history_navigation()\n",
    "    \n",
    "    def update_history_navigation(self):\n",
    "        \"\"\"Update history navigation buttons and label\"\"\"\n",
    "        total = len(self.process_history)\n",
    "        current = self.current_history_index + 1 if total > 0 else 0\n",
    "        \n",
    "        self.history_label.configure(text=f\"{current}/{total}\")\n",
    "        \n",
    "        # Update button states\n",
    "        self.prev_button.configure(state=\"normal\" if self.current_history_index > 0 else \"disabled\")\n",
    "        self.next_button.configure(state=\"normal\" if self.current_history_index < total - 1 else \"disabled\")\n",
    "    \n",
    "    def add_to_history(self, prompt: str, result: str):\n",
    "        \"\"\"Add a new result to history\"\"\"\n",
    "        self.process_history.append((prompt, result))\n",
    "        self.current_history_index = len(self.process_history) - 1\n",
    "        self.update_history_navigation()\n",
    "    \n",
    "    def check_error_queue(self):\n",
    "        \"\"\"Check for errors from background threads\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                error_type, error_msg = self.error_queue.get_nowait()\n",
    "                messagebox.showerror(error_type, error_msg)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.after(100, self.check_error_queue)\n",
    "    \n",
    "    def save_api_key(self):\n",
    "        \"\"\"Save API key for session\"\"\"\n",
    "        api_key = self.api_key_entry.get()\n",
    "        if api_key:\n",
    "            self.api_key = api_key\n",
    "            self.save_api_button.configure(text=\"✓\")\n",
    "            self.after(2000, lambda: self.save_api_button.configure(text=\"Save\"))\n",
    "            self.update_status(\"API key saved\")\n",
    "            self.update_button_states()  # Add this line\n",
    "    \n",
    "    def copy_to_clipboard(self):\n",
    "        \"\"\"Copy current tab content to clipboard\"\"\"\n",
    "        current_tab = self.tabview.get()\n",
    "        if \"Transcription\" in current_tab and self.transcribed_text:\n",
    "            self.clipboard_clear()\n",
    "            self.clipboard_append(self.transcribed_text)\n",
    "            self.update_status(\"Transcription copied to clipboard\")\n",
    "        elif \"Result\" in current_tab and self.current_history_index >= 0:\n",
    "            _, result = self.process_history[self.current_history_index]\n",
    "            self.clipboard_clear()\n",
    "            self.clipboard_append(result)\n",
    "            self.update_status(\"Result copied to clipboard\")\n",
    "        else:\n",
    "            self.update_status(\"No content to copy\")\n",
    "    \n",
    "    def load_whisper_model(self):\n",
    "        \"\"\"Load Whisper model in background thread\"\"\"\n",
    "        if self.model_loading:\n",
    "            return\n",
    "            \n",
    "        def load():\n",
    "            self.model_loading = True\n",
    "            self.after(0, lambda: self.update_status(\"Loading Whisper model...\"))\n",
    "            self.after(0, lambda: self.model_status.configure(text=\"🟡 Loading...\"))\n",
    "            \n",
    "            try:\n",
    "                model_name = self.model_var.get()\n",
    "                self.whisper_model = whisper.load_model(model_name)\n",
    "                \n",
    "                self.after(0, lambda: self.update_status(\"Whisper model loaded\"))\n",
    "                self.after(0, lambda: self.model_status.configure(text=\"🟢 Ready\"))\n",
    "                self.after(0, lambda: self.update_button_states())\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Model Load Error\", f\"Failed to load Whisper model: {str(e)}\"))\n",
    "                self.after(0, lambda: self.model_status.configure(text=\"🔴 Error\"))\n",
    "            finally:\n",
    "                self.model_loading = False\n",
    "        \n",
    "        threading.Thread(target=load, daemon=True).start()\n",
    "\n",
    "    def show_network_plot_in_panel(self, plot_path):\n",
    "        \"\"\"Display network plot in the visualization panel with dynamic resizing\"\"\"\n",
    "        try:\n",
    "            from PIL import Image, ImageTk\n",
    "            \n",
    "            # Store the plot path for resizing\n",
    "            self.current_network_plot_path = plot_path\n",
    "            \n",
    "            # Load the original image\n",
    "            img = Image.open(plot_path)\n",
    "            \n",
    "            # Get the current size of the network display area\n",
    "            display_width = self.network_display.winfo_width()\n",
    "            display_height = self.network_display.winfo_height()\n",
    "            \n",
    "            # If display area is not yet rendered, use default sizes\n",
    "            if display_width <= 1 or display_height <= 1:\n",
    "                display_width = 500\n",
    "                display_height = 400\n",
    "            \n",
    "            # Calculate scaling to maintain aspect ratio with padding\n",
    "            padding = 20\n",
    "            max_width = display_width - padding\n",
    "            max_height = display_height - padding\n",
    "            \n",
    "            img_width, img_height = img.size\n",
    "            scale = min(max_width/img_width, max_height/img_height)\n",
    "            \n",
    "            # Limit maximum scale to avoid pixelation\n",
    "            scale = min(scale, 2.0)\n",
    "            \n",
    "            new_width = int(img_width * scale)\n",
    "            new_height = int(img_height * scale)\n",
    "            \n",
    "            # Resize image with high quality\n",
    "            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Convert to PhotoImage\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            \n",
    "            # Update the network display label with the image\n",
    "            self.network_display.configure(image=photo, text=\"\")\n",
    "            self.network_display.image = photo  # Keep a reference\n",
    "            self.network_photo = photo  # Store reference for resizing\n",
    "            \n",
    "            # Enable refresh button\n",
    "            if hasattr(self, 'refresh_network_btn'):\n",
    "                self.refresh_network_btn.configure(state=\"normal\")\n",
    "            \n",
    "            # Add or update save button\n",
    "            if not hasattr(self, 'save_network_btn'):\n",
    "                self.save_network_btn = ctk.CTkButton(\n",
    "                    self.network_frame,\n",
    "                    text=\"💾 Save Plot\",\n",
    "                    command=lambda: self.save_network_plot(plot_path),\n",
    "                    height=30\n",
    "                )\n",
    "                self.save_network_btn.grid(row=2, column=0, pady=5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_queue.put((\"Display Error\", f\"Failed to display network plot: {str(e)}\"))\n",
    "\n",
    "    def create_network_plot(self):\n",
    "        \"\"\"Create a network plot using Word2Vec embeddings with user-selectable clustering\"\"\"\n",
    "        if not self.transcribed_text:\n",
    "            messagebox.showwarning(\"No Content\", \"No transcription available for network plot\")\n",
    "            return\n",
    "        \n",
    "        api_key = self.api_key_entry.get() or self.api_key\n",
    "        if not api_key:\n",
    "            messagebox.showwarning(\"API Key Required\", \"Please enter your Anthropic API key\")\n",
    "            return\n",
    "        \n",
    "        # Ask user for number of clusters\n",
    "        cluster_dialog = ctk.CTkInputDialog(\n",
    "            text=\"Enter number of clusters (2-10):\",\n",
    "            title=\"Cluster Configuration\"\n",
    "        )\n",
    "        n_clusters_str = cluster_dialog.get_input()\n",
    "        \n",
    "        try:\n",
    "            n_clusters = int(n_clusters_str) if n_clusters_str else 5\n",
    "            n_clusters = max(2, min(10, n_clusters))\n",
    "        except:\n",
    "            n_clusters = 5\n",
    "        \n",
    "        def generate_plot():\n",
    "            try:\n",
    "                self.after(0, lambda: self.network_button.configure(state=\"disabled\"))\n",
    "                self.after(0, lambda: self.update_status(\"Loading Word2Vec model...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.1))\n",
    "                \n",
    "                # Load or cache Word2Vec model with better error handling\n",
    "                if self.word2vec_model is None:\n",
    "                    try:\n",
    "                        import gensim.downloader as api\n",
    "                        # Try to load a smaller, faster model first\n",
    "                        self.after(0, lambda: self.update_status(\"Downloading Word2Vec model (first time only)...\"))\n",
    "                        self.word2vec_model = api.load('glove-wiki-gigaword-50')\n",
    "                    except Exception as e:\n",
    "                        self.error_queue.put((\"Model Error\", f\"Failed to load Word2Vec model: {str(e)}\\nPlease install: pip install gensim\"))\n",
    "                        return\n",
    "                \n",
    "                self.after(0, lambda: self.update_status(\"Processing text with Word2Vec...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.3))\n",
    "                \n",
    "                # Preprocess text\n",
    "                text = self.transcribed_text.lower()\n",
    "                words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "                \n",
    "                # Enhanced stop words list\n",
    "                stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
    "                             'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',\n",
    "                             'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
    "                             'would', 'could', 'should', 'may', 'might', 'must', 'shall', 'can',\n",
    "                             'need', 'dare', 'ought', 'used', 'i', 'you', 'he', 'she', 'it', 'we',\n",
    "                             'they', 'them', 'their', 'this', 'that', 'these', 'those'}\n",
    "                \n",
    "                # Filter words and keep only those in Word2Vec vocabulary\n",
    "                filtered_words = []\n",
    "                for w in words:\n",
    "                    if w not in stop_words and len(w) > 2:\n",
    "                        try:\n",
    "                            # Check if word is in model vocabulary\n",
    "                            if hasattr(self.word2vec_model, 'key_to_index'):\n",
    "                                if w in self.word2vec_model.key_to_index:\n",
    "                                    filtered_words.append(w)\n",
    "                            elif w in self.word2vec_model:\n",
    "                                filtered_words.append(w)\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                if len(filtered_words) < 5:\n",
    "                    self.error_queue.put((\"Insufficient Data\", \"Not enough words found in the Word2Vec vocabulary. The text may be too short or contain specialized terms.\"))\n",
    "                    return\n",
    "                \n",
    "                # Get most frequent words that have embeddings\n",
    "                word_freq = Counter(filtered_words)\n",
    "                top_words = [word for word, freq in word_freq.most_common(150)]\n",
    "                \n",
    "                if len(top_words) < 5:\n",
    "                    self.error_queue.put((\"Insufficient Data\", \"Not enough words with embeddings found. Try with longer text.\"))\n",
    "                    return\n",
    "                \n",
    "                # Get Word2Vec embeddings\n",
    "                embeddings = []\n",
    "                valid_words = []\n",
    "                for word in top_words:\n",
    "                    try:\n",
    "                        if hasattr(self.word2vec_model, 'get_vector'):\n",
    "                            embeddings.append(self.word2vec_model.get_vector(word))\n",
    "                        else:\n",
    "                            embeddings.append(self.word2vec_model[word])\n",
    "                        valid_words.append(word)\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                if len(embeddings) < 5:\n",
    "                    self.error_queue.put((\"Insufficient Embeddings\", \"Not enough word embeddings found. The text may be too specialized.\"))\n",
    "                    return\n",
    "                \n",
    "                embeddings = np.array(embeddings)\n",
    "                \n",
    "                self.after(0, lambda: self.update_status(\"Clustering words in embedding space...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.4))\n",
    "                \n",
    "                # Perform clustering in high-dimensional space\n",
    "                from sklearn.cluster import KMeans\n",
    "                n_clusters_actual = min(n_clusters, len(valid_words) // 2)\n",
    "                kmeans = KMeans(n_clusters=n_clusters_actual, random_state=42, n_init=10)\n",
    "                cluster_labels = kmeans.fit_predict(embeddings)\n",
    "                \n",
    "                # Create co-occurrence information for edge weights\n",
    "                window_size = 7\n",
    "                co_occurrences = {}\n",
    "                word_positions = {word: [] for word in valid_words}\n",
    "                \n",
    "                # Record positions of valid words\n",
    "                for i, word in enumerate(filtered_words):\n",
    "                    if word in valid_words:\n",
    "                        word_positions[word].append(i)\n",
    "                \n",
    "                # Calculate co-occurrences with distance weighting\n",
    "                for word1 in valid_words:\n",
    "                    for word2 in valid_words:\n",
    "                        if word1 != word2:\n",
    "                            pair = tuple(sorted([word1, word2]))\n",
    "                            if pair not in co_occurrences:\n",
    "                                co_occurrences[pair] = 0\n",
    "                                for pos1 in word_positions[word1]:\n",
    "                                    for pos2 in word_positions[word2]:\n",
    "                                        distance = abs(pos1 - pos2)\n",
    "                                        if distance <= window_size:\n",
    "                                            # Weight by inverse distance\n",
    "                                            co_occurrences[pair] += 1.0 / (1 + distance)\n",
    "                \n",
    "                self.after(0, lambda: self.update_status(\"Projecting to 2D space...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.5))\n",
    "                \n",
    "                # Project to 2D using t-SNE for better visualization\n",
    "                from sklearn.manifold import TSNE\n",
    "                from sklearn.decomposition import PCA\n",
    "                \n",
    "                if len(embeddings) > 30:\n",
    "                    # Use PCA first for dimensionality reduction if many words\n",
    "                    pca = PCA(n_components=min(30, len(embeddings)-1))\n",
    "                    embeddings_reduced = pca.fit_transform(embeddings)\n",
    "                    tsne = TSNE(n_components=2, perplexity=min(30, len(embeddings)-1), \n",
    "                               random_state=42, n_iter=1000)\n",
    "                    coords_2d = tsne.fit_transform(embeddings_reduced)\n",
    "                else:\n",
    "                    perplexity = min(5, len(embeddings)-1)  # Ensure perplexity is valid\n",
    "                    tsne = TSNE(n_components=2, perplexity=perplexity, \n",
    "                               random_state=42, n_iter=1000)\n",
    "                    coords_2d = tsne.fit_transform(embeddings)\n",
    "                \n",
    "                # Create network graph\n",
    "                import networkx as nx\n",
    "                G = nx.Graph()\n",
    "                \n",
    "                # Add nodes with positions and attributes\n",
    "                for i, word in enumerate(valid_words):\n",
    "                    G.add_node(word, \n",
    "                              pos=(coords_2d[i, 0], coords_2d[i, 1]),\n",
    "                              cluster=cluster_labels[i],\n",
    "                              weight=word_freq[word])\n",
    "                \n",
    "                # Add edges based only on co-occurrence from the transcript\n",
    "                for i, word1 in enumerate(valid_words):\n",
    "                    for j, word2 in enumerate(valid_words[i+1:], i+1):\n",
    "                        pair = tuple(sorted([word1, word2]))\n",
    "                        co_occur = co_occurrences.get(pair, 0)\n",
    "                        \n",
    "                        # Add edge only if words co-occur in the transcript\n",
    "                        if co_occur > 0.25:  # Threshold for meaningful co-occurrence\n",
    "                            G.add_edge(word1, word2, weight=co_occur)\n",
    "                \n",
    "                self.after(0, lambda: self.update_status(\"Creating visualization...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.7))\n",
    "                \n",
    "                # Create visualization\n",
    "                import matplotlib.pyplot as plt\n",
    "                fig, ax = plt.subplots(figsize=(10, 8))\n",
    "                fig.patch.set_facecolor('#f0f0f0')\n",
    "                ax.set_facecolor('#ffffff')\n",
    "                \n",
    "                # Use positions from t-SNE (semantic positioning)\n",
    "                pos = nx.get_node_attributes(G, 'pos')\n",
    "                \n",
    "                # Color scheme for clusters\n",
    "                colors = plt.cm.Set3(np.linspace(0, 1, n_clusters_actual))\n",
    "                node_colors = [colors[G.nodes[node]['cluster']] for node in G.nodes()]\n",
    "                \n",
    "                # Node sizes based on word frequency\n",
    "                node_sizes = [200 + G.nodes[node]['weight'] * 20 for node in G.nodes()]\n",
    "                \n",
    "                # Draw edges with varying thickness based on co-occurrence strength\n",
    "                edges = G.edges()\n",
    "                if edges:\n",
    "                    edge_weights = [G[u][v]['weight'] for u, v in edges]\n",
    "                    max_weight = max(edge_weights) if edge_weights else 1\n",
    "                    \n",
    "                    # Draw edges with thickness proportional to co-occurrence\n",
    "                    for (u, v), weight in zip(edges, edge_weights):\n",
    "                        alpha = 0.3 + (weight / max_weight) * 0.5\n",
    "                        width = 0.5 + (weight / max_weight) * 3\n",
    "                        nx.draw_networkx_edges(G, pos, [(u, v)], alpha=alpha, \n",
    "                                             width=width, edge_color='#666666', ax=ax)\n",
    "                \n",
    "                # Draw nodes\n",
    "                nx.draw_networkx_nodes(G, pos, node_color=node_colors, \n",
    "                                     node_size=node_sizes, alpha=0.85,\n",
    "                                     edgecolors='black', linewidths=1.5, ax=ax)\n",
    "                \n",
    "                # Draw labels\n",
    "                labels = {node: node for node in G.nodes()}\n",
    "                nx.draw_networkx_labels(G, pos, labels, font_size=8, \n",
    "                                       font_weight='bold', ax=ax)\n",
    "                \n",
    "                # Add title\n",
    "                ax.set_title(\"Semantic Network: Word2Vec Similarity & Co-occurrence\", \n",
    "                            fontsize=12, fontweight='bold', pad=20)\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Add cluster legend\n",
    "                for i in range(n_clusters_actual):\n",
    "                    cluster_words = [w for w in valid_words if cluster_labels[valid_words.index(w)] == i][:3]\n",
    "                    label = f\"Cluster {i+1}: {', '.join(cluster_words[:3])}...\"\n",
    "                    ax.scatter([], [], c=[colors[i]], s=150, label=label, alpha=0.85)\n",
    "                \n",
    "                ax.legend(loc='upper left', frameon=True, fancybox=True, \n",
    "                         shadow=True, fontsize=8)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save plot\n",
    "                plot_path = Path(\"network_analysis.png\")\n",
    "                plt.savefig(plot_path, dpi=150, bbox_inches='tight', \n",
    "                           facecolor='#f0f0f0', edgecolor='none')\n",
    "                plt.close()\n",
    "                \n",
    "                # Display plot in the panel instead of new window\n",
    "                self.after(0, lambda: self.show_network_plot_in_panel(plot_path))\n",
    "                self.after(0, lambda: self.update_status(\"Network plot generated successfully\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(1.0))\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Plot Error\", f\"Failed to generate network plot: {str(e)}\"))\n",
    "            finally:\n",
    "                self.after(0, lambda: self.progress_bar.set(0))\n",
    "                self.after(0, lambda: self.network_button.configure(state=\"normal\"))\n",
    "                if hasattr(self, 'refresh_network_btn'):\n",
    "                    self.after(0, lambda: self.refresh_network_btn.configure(state=\"normal\"))\n",
    "        \n",
    "        threading.Thread(target=generate_plot, daemon=True).start()\n",
    "    \n",
    "    def on_model_change(self, value):\n",
    "        \"\"\"Handle model selection change\"\"\"\n",
    "        self.whisper_model = None\n",
    "        self.model_status.configure(text=\"⚪ Not loaded\")\n",
    "        self.update_button_states()\n",
    "        self.load_whisper_model()\n",
    "    \n",
    "    def select_audio_file(self):\n",
    "        \"\"\"Open file dialog to select audio/video file\"\"\"\n",
    "        file_types = [\n",
    "            (\"Audio/Video files\", \"*.mp3 *.wav *.m4a *.flac *.aac *.ogg *.wma *.mp4 *.mov *.avi *.mkv *.webm *.m4v\"),\n",
    "            (\"Audio files\", \"*.mp3 *.wav *.m4a *.flac *.aac *.ogg *.wma\"),\n",
    "            (\"Video files\", \"*.mp4 *.mov *.avi *.mkv *.webm *.m4v\"),\n",
    "            (\"MP3 files\", \"*.mp3\"),\n",
    "            (\"MP4 files\", \"*.mp4\"),\n",
    "            (\"WAV files\", \"*.wav\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ]\n",
    "        \n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select Audio/Video File\",\n",
    "            filetypes=file_types\n",
    "        )\n",
    "        \n",
    "        if file_path:\n",
    "            self.audio_file_path = file_path\n",
    "            filename = os.path.basename(file_path)\n",
    "            self.file_label.configure(text=f\"Selected: {filename}\")\n",
    "            \n",
    "            # Update valid range for the new file\n",
    "            self.update_valid_range()\n",
    "            \n",
    "            # Reset transcription when new file is loaded\n",
    "            self.transcribed_text = \"\"\n",
    "            self.trans_text.delete(\"1.0\", \"end\")\n",
    "            self.trans_word_count.configure(text=\"Words: 0 | Characters: 0\")\n",
    "            self.trans_status.configure(text=\"Ready to transcribe\", text_color=(\"gray50\", \"gray50\"))\n",
    "            \n",
    "            # Clear network display and semantic summary\n",
    "            if hasattr(self, 'network_display'):\n",
    "                self.network_display.configure(\n",
    "                    text=\"No network generated yet\\n\\nClick 'Generate Network Plot' to visualize\",\n",
    "                    image=None\n",
    "                )\n",
    "                if hasattr(self.network_display, 'image'):\n",
    "                    self.network_display.image = None\n",
    "            \n",
    "            if hasattr(self, 'semantic_summary_text'):\n",
    "                self.semantic_summary_text.configure(state=\"normal\")\n",
    "                self.semantic_summary_text.delete(\"1.0\", \"end\")\n",
    "                self.semantic_summary_text.insert(\"1.0\", \"No summary generated yet.\\n\\nClick 'Generate' to create a semantic summary of the transcribed text.\")\n",
    "                self.semantic_summary_text.configure(state=\"disabled\")\n",
    "            \n",
    "            # Update button states\n",
    "            self.update_button_states()\n",
    "            \n",
    "            # Determine file type for status message\n",
    "            file_ext = os.path.splitext(file_path)[1].lower()\n",
    "            video_extensions = {'.mp4', '.mov', '.avi', '.mkv', '.webm', '.m4v'}\n",
    "            file_type = \"video\" if file_ext in video_extensions else \"audio\"\n",
    "            self.update_status(f\"{file_type.capitalize()} file selected: {filename}\")\n",
    "    \n",
    "    def update_button_states(self):\n",
    "        \"\"\"Update all button states based on current conditions including translation\"\"\"\n",
    "        \n",
    "        # Get current API key\n",
    "        current_api_key = self.api_key if self.api_key else self.api_key_entry.get()\n",
    "        \n",
    "        # Transcribe button - ALWAYS enable if we have a file AND model is loaded\n",
    "        if self.audio_file_path and self.whisper_model:\n",
    "            self.transcribe_button.configure(state=\"normal\", fg_color=(\"#1f538d\", \"#14375e\"))\n",
    "        else:\n",
    "            self.transcribe_button.configure(state=\"disabled\", fg_color=(\"gray75\", \"gray25\"))\n",
    "        \n",
    "        # Clean button - enable if we have transcribed text AND API key\n",
    "        if self.transcribed_text and current_api_key:\n",
    "            self.clean_button.configure(state=\"normal\", fg_color=(\"#1f538d\", \"#14375e\"))\n",
    "        else:\n",
    "            self.clean_button.configure(state=\"disabled\", fg_color=(\"gray75\", \"gray25\"))\n",
    "        \n",
    "        # Network button - enable if we have transcribed text AND API key\n",
    "        if self.transcribed_text and current_api_key:\n",
    "            self.network_button.configure(state=\"normal\", fg_color=(\"#1f538d\", \"#14375e\"))\n",
    "            if hasattr(self, 'refresh_network_btn'):\n",
    "                self.refresh_network_btn.configure(state=\"normal\")\n",
    "        else:\n",
    "            self.network_button.configure(state=\"disabled\", fg_color=(\"gray75\", \"gray25\"))\n",
    "            if hasattr(self, 'refresh_network_btn'):\n",
    "                self.refresh_network_btn.configure(state=\"disabled\")\n",
    "        \n",
    "        # Summarize button - enable if we have transcribed text AND API key\n",
    "        if self.transcribed_text and current_api_key:\n",
    "            self.summarize_button.configure(state=\"normal\", fg_color=(\"#1f538d\", \"#14375e\"))\n",
    "        else:\n",
    "            self.summarize_button.configure(state=\"disabled\", fg_color=(\"gray75\", \"gray25\"))\n",
    "        \n",
    "        # Translate button - enable if we have transcribed text AND API key\n",
    "        if hasattr(self, 'translate_button'):\n",
    "            if self.transcribed_text and current_api_key:\n",
    "                self.translate_button.configure(state=\"normal\", fg_color=(\"#1f538d\", \"#14375e\"))\n",
    "            else:\n",
    "                self.translate_button.configure(state=\"disabled\", fg_color=(\"gray75\", \"gray25\"))\n",
    "        \n",
    "        # Custom prompt button - enable if we have transcribed text AND API key\n",
    "        if self.transcribed_text and current_api_key:\n",
    "            self.process_custom_button.configure(state=\"normal\")\n",
    "        else:\n",
    "            self.process_custom_button.configure(state=\"disabled\")\n",
    "        \n",
    "        # Semantic summary button - enable if we have transcribed text AND API key\n",
    "        if self.transcribed_text and current_api_key:\n",
    "            if hasattr(self, 'generate_summary_btn'):\n",
    "                self.generate_summary_btn.configure(state=\"normal\")\n",
    "        else:\n",
    "            if hasattr(self, 'generate_summary_btn'):\n",
    "                self.generate_summary_btn.configure(state=\"disabled\")\n",
    "        \n",
    "        # Update time segment inputs when duration info changes\n",
    "        if hasattr(self, 'start_time_entry'):\n",
    "            self.start_time_entry.bind(\"<KeyRelease>\", lambda e: self.update_duration_info())\n",
    "            self.end_time_entry.bind(\"<KeyRelease>\", lambda e: self.update_duration_info())\n",
    "\n",
    "    def generate_semantic_summary(self):\n",
    "        \"\"\"Generate ONE sentence that captures BOTH semantics and tone.\"\"\"\n",
    "        if not self.transcribed_text:\n",
    "            messagebox.showwarning(\"No Content\", \"No transcription available for summary\")\n",
    "            return\n",
    "    \n",
    "        api_key = self.api_key_entry.get() or self.api_key\n",
    "        if not api_key:\n",
    "            messagebox.showwarning(\"API Key Required\", \"Please enter your Anthropic API key\")\n",
    "            return\n",
    "    \n",
    "        def generate():\n",
    "            try:\n",
    "                self.after(0, lambda: self.generate_summary_btn.configure(state=\"disabled\"))\n",
    "                self.after(0, lambda: self.update_status(\"Generating semantic & tone summary...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.5))\n",
    "    \n",
    "                client = Anthropic(api_key=api_key)\n",
    "                text_to_summarize = self.transcribed_text\n",
    "    \n",
    "                prompt = f\"\"\"You will receive a transcript. Write EXACTLY ONE sentence (≤ 30 words) that captures BOTH:\n",
    "    - the core meaning/topic, and\n",
    "    - the overall tone/affect/delivery style (e.g., enthusiastic, cautious, frustrated, formal).\n",
    "    \n",
    "    Rules:\n",
    "    - Single sentence only; end with a period.\n",
    "    - ≤ 30 words.\n",
    "    - No quotes, labels, lists, JSON, or extra commentary.\n",
    "    - No markdown.\n",
    "    \n",
    "    Transcript:\n",
    "    {text_to_summarize}\"\"\"\n",
    "    \n",
    "                response = client.messages.create(\n",
    "                    model=\"claude-sonnet-4-20250514\",\n",
    "                    max_tokens=150,\n",
    "                    temperature=0.2,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "    \n",
    "                raw = response.content[0].text.strip()\n",
    "    \n",
    "                # --- Post-process to enforce one sentence and ≤ 30 words ---\n",
    "                s = raw.replace(\"\\n\", \" \").strip()\n",
    "                s = s.strip(' \"\\'')  # remove leading/trailing quotes if any\n",
    "    \n",
    "                import re\n",
    "                # Keep only the first sentence boundary encountered\n",
    "                parts = re.split(r'(?<=[.!?])\\s+', s)\n",
    "                s = parts[0].strip() if parts else s\n",
    "    \n",
    "                # Ensure it ends with a sentence terminator\n",
    "                if not s.endswith(('.', '!', '?')):\n",
    "                    s += '.'\n",
    "    \n",
    "                # Enforce ≤ 30 words\n",
    "                words = s.split()\n",
    "                if len(words) > 30:\n",
    "                    s = \" \".join(words[:30]).rstrip('.,;:!?') + \".\"\n",
    "    \n",
    "                self.after(0, lambda: self.update_semantic_summary_display(s))\n",
    "                self.after(0, lambda: self.update_status(\"Semantic & tone summary generated\"))\n",
    "    \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Summary Error\", f\"Failed to generate summary: {str(e)}\"))\n",
    "            finally:\n",
    "                self.after(0, lambda: self.progress_bar.set(0))\n",
    "                self.after(0, lambda: self.generate_summary_btn.configure(state=\"normal\"))\n",
    "    \n",
    "        threading.Thread(target=generate, daemon=True).start()\n",
    "    \n",
    "    def update_semantic_summary_display(self, summary):\n",
    "        \"\"\"Update the semantic summary display in the visualization panel\"\"\"\n",
    "        self.semantic_summary_text.configure(state=\"normal\")\n",
    "        self.semantic_summary_text.delete(\"1.0\", \"end\")\n",
    "        self.semantic_summary_text.insert(\"1.0\", summary)\n",
    "        self.semantic_summary_text.configure(state=\"disabled\")\n",
    "        \n",
    "        # Add timestamp\n",
    "        from datetime import datetime\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Update with timestamp info\n",
    "        self.semantic_summary_text.configure(state=\"normal\")\n",
    "        self.semantic_summary_text.insert(\"end\", f\"\\n\\n[Generated at {timestamp}]\")\n",
    "        self.semantic_summary_text.configure(state=\"disabled\")\n",
    "    \n",
    "    def update_status(self, message: str):\n",
    "        \"\"\"Update status label\"\"\"\n",
    "        self.status_label.configure(text=message)\n",
    "    \n",
    "    def start_transcription(self):\n",
    "        \"\"\"Start transcription in background thread with time segment support\"\"\"\n",
    "        if not self.audio_file_path or not self.whisper_model:\n",
    "            return\n",
    "        \n",
    "        # Validate time segment\n",
    "        if not self.validate_time_segment():\n",
    "            return\n",
    "        \n",
    "        # Get time segment parameters\n",
    "        start_time, end_time = self.get_time_segment_params()\n",
    "        \n",
    "        def transcribe():\n",
    "            try:\n",
    "                # Determine file type for status message\n",
    "                file_ext = os.path.splitext(self.audio_file_path)[1].lower()\n",
    "                video_extensions = {'.mp4', '.mov', '.avi', '.mkv', '.webm', '.m4v'}\n",
    "                file_type = \"video\" if file_ext in video_extensions else \"audio\"\n",
    "                \n",
    "                # Update status with segment info\n",
    "                if start_time is not None and end_time is not None:\n",
    "                    segment_info = f\" (segment: {start_time:.1f}s - {end_time:.1f}s)\"\n",
    "                else:\n",
    "                    segment_info = \" (full)\"\n",
    "                \n",
    "                self.after(0, lambda: self.update_status(f\"Transcribing {file_type}{segment_info}...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.1))\n",
    "                self.after(0, lambda: self.transcribe_button.configure(state=\"disabled\"))\n",
    "                \n",
    "                # Prepare transcription parameters\n",
    "                transcribe_params = {}\n",
    "                \n",
    "                # Handle time segments\n",
    "                if start_time is not None and end_time is not None:\n",
    "                    # For time segments, we need to extract the segment first\n",
    "                    import tempfile\n",
    "                    import subprocess\n",
    "                    \n",
    "                    # Create temporary file for segment\n",
    "                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:\n",
    "                        temp_path = temp_file.name\n",
    "                    \n",
    "                    try:\n",
    "                        # Extract segment using ffmpeg\n",
    "                        duration = end_time - start_time\n",
    "                        cmd = [\n",
    "                            'ffmpeg', '-i', self.audio_file_path,\n",
    "                            '-ss', str(start_time),\n",
    "                            '-t', str(duration),\n",
    "                            '-acodec', 'pcm_s16le',\n",
    "                            '-ar', '16000',\n",
    "                            '-ac', '1',\n",
    "                            '-y',  # Overwrite output file\n",
    "                            temp_path\n",
    "                        ]\n",
    "                        \n",
    "                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n",
    "                        \n",
    "                        if result.returncode != 0:\n",
    "                            # If ffmpeg fails, try alternative approach with Whisper's built-in segment handling\n",
    "                            # This is less accurate but works as fallback\n",
    "                            self.after(0, lambda: self.update_status(\"Using alternative segment extraction...\"))\n",
    "                            audio_path = self.audio_file_path\n",
    "                            \n",
    "                            # Whisper doesn't have built-in segment support, so we'll process full and trim text\n",
    "                            # This is a workaround - ideally ffmpeg should work\n",
    "                            transcribe_params['initial_prompt'] = f\"[Transcribe from {start_time:.1f}s to {end_time:.1f}s]\"\n",
    "                        else:\n",
    "                            audio_path = temp_path\n",
    "                        \n",
    "                        # Transcribe the segment\n",
    "                        result = self.whisper_model.transcribe(audio_path, **transcribe_params)\n",
    "                        transcribed_text = result[\"text\"]\n",
    "                        \n",
    "                    finally:\n",
    "                        # Clean up temporary file\n",
    "                        if 'temp_path' in locals() and os.path.exists(temp_path):\n",
    "                            try:\n",
    "                                os.remove(temp_path)\n",
    "                            except:\n",
    "                                pass\n",
    "                else:\n",
    "                    # Transcribe full audio\n",
    "                    result = self.whisper_model.transcribe(self.audio_file_path, **transcribe_params)\n",
    "                    transcribed_text = result[\"text\"]\n",
    "                \n",
    "                # Update UI on main thread\n",
    "                self.after(0, lambda: self.update_transcription_result(transcribed_text))\n",
    "                \n",
    "                # Store segment info for reference\n",
    "                self.last_transcription_segment = (start_time, end_time)\n",
    "                \n",
    "            except subprocess.TimeoutExpired:\n",
    "                self.error_queue.put((\"Transcription Error\", \"Segment extraction timed out. Try a shorter segment.\"))\n",
    "            except FileNotFoundError:\n",
    "                self.error_queue.put((\"FFmpeg Error\", \"FFmpeg not found. Please install FFmpeg for time segment support.\"))\n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Transcription Error\", f\"Failed to transcribe {file_type}: {str(e)}\"))\n",
    "            finally:\n",
    "                self.after(0, lambda: self.progress_bar.set(0))\n",
    "                self.after(0, lambda: self.update_button_states())\n",
    "        \n",
    "        threading.Thread(target=transcribe, daemon=True).start()\n",
    "    \n",
    "    def update_transcription_result(self, text: str):\n",
    "        \"\"\"Update transcription result in UI\"\"\"\n",
    "        self.transcribed_text = text\n",
    "        self.trans_text.delete(\"1.0\", \"end\")\n",
    "        self.trans_text.insert(\"1.0\", text)\n",
    "        \n",
    "        # Update word count\n",
    "        words = len(text.split())\n",
    "        chars = len(text)\n",
    "        self.trans_word_count.configure(text=f\"Words: {words} | Characters: {chars}\")\n",
    "        self.trans_status.configure(text=\"Transcription complete\", text_color=(\"green\", \"lightgreen\"))\n",
    "        \n",
    "        self.update_status(\"Transcription completed\")\n",
    "        self.progress_bar.set(1.0)\n",
    "        self.update_button_states()\n",
    "    \n",
    "    def summarize_transcription(self):\n",
    "        \"\"\"Summarize transcription using Claude\"\"\"\n",
    "        if not self.transcribed_text:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            word_limit = int(self.word_limit_var.get() or \"500\")\n",
    "        except ValueError:\n",
    "            word_limit = 500\n",
    "        \n",
    "        prompt = self.get_summarize_prompt(self.transcribed_text, word_limit)\n",
    "        \n",
    "        def process():\n",
    "            try:\n",
    "                self.after(0, lambda: self.summarize_button.configure(state=\"disabled\"))\n",
    "                \n",
    "                result = self.process_with_claude_enhanced(self.transcribed_text, prompt)\n",
    "                \n",
    "                if result:\n",
    "                    self.after(0, lambda: self.update_result(prompt, result))\n",
    "                    self.after(0, lambda: self.update_status(\"Summarization completed\"))\n",
    "                else:\n",
    "                    self.after(0, lambda: self.update_status(\"Summarization failed\"))\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Processing Error\", f\"Failed to process: {str(e)}\"))\n",
    "            finally:\n",
    "                self.after(0, lambda: self.progress_bar.set(0))\n",
    "                self.after(0, lambda: self.update_button_states())\n",
    "        \n",
    "        threading.Thread(target=process, daemon=True).start()\n",
    "    \n",
    "    def process_custom_prompt(self):\n",
    "        \"\"\"Process custom prompt with Claude\"\"\"\n",
    "        if not self.transcribed_text:\n",
    "            return\n",
    "        \n",
    "        custom_prompt = self.custom_prompt_text.get(\"1.0\", \"end-1c\")\n",
    "        \n",
    "        # Replace {text} placeholder with actual transcription\n",
    "        prompt = custom_prompt.replace(\"{text}\", self.transcribed_text)\n",
    "        \n",
    "        def process():\n",
    "            try:\n",
    "                self.after(0, lambda: self.process_custom_button.configure(state=\"disabled\"))\n",
    "                \n",
    "                result = self.process_with_claude_enhanced(self.transcribed_text, prompt)\n",
    "                \n",
    "                if result:\n",
    "                    self.after(0, lambda: self.update_result(custom_prompt, result))\n",
    "                    self.after(0, lambda: self.update_status(\"Custom prompt processed\"))\n",
    "                else:\n",
    "                    self.after(0, lambda: self.update_status(\"Processing failed\"))\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Processing Error\", f\"Failed to process: {str(e)}\"))\n",
    "            finally:\n",
    "                self.after(0, lambda: self.progress_bar.set(0))\n",
    "                self.after(0, lambda: self.update_button_states())\n",
    "        \n",
    "        threading.Thread(target=process, daemon=True).start()\n",
    "    \n",
    "    def update_result(self, prompt: str, result: str):\n",
    "        \"\"\"Update result in UI and add to history\"\"\"\n",
    "        self.add_to_history(prompt, result)\n",
    "        \n",
    "        self.result_text.delete(\"1.0\", \"end\")\n",
    "        self.result_text.insert(\"1.0\", result)\n",
    "        \n",
    "        self.result_status.configure(text=\"Processing complete\", text_color=(\"green\", \"lightgreen\"))\n",
    "        \n",
    "        # Switch to result tab\n",
    "        self.tabview.set(\"✨ Processed Result\")\n",
    "    \n",
    "    def get_summarize_prompt(self, text: str, word_limit: int) -> str:\n",
    "        \"\"\"Generate summarization prompt with word limit\"\"\"\n",
    "        output_format = self.output_format.get().lower()\n",
    "        \n",
    "        format_instructions = {\n",
    "            \"markdown\": \"Format your response in clean Markdown with appropriate headers and structure.\",\n",
    "            \"plain text\": \"Provide a plain text response without any formatting.\",\n",
    "            \"json\": \"Return your response as a well-structured JSON object.\",\n",
    "            \"bullet points\": \"Structure your response as clear bullet points.\",\n",
    "            \"latex pdf\": \"Format your response in LaTeX document format with proper document class, sections, and formatting.\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"Please provide a comprehensive summary of the following transcribed audio content in approximately {word_limit} words. \n",
    "        Focus on the main ideas, key points, and important details. \n",
    "        {format_instructions.get(output_format, '')}\n",
    "        \n",
    "        Transcribed text:\n",
    "        {text}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def process_with_claude_enhanced(self, text: str, prompt: str, is_translation: bool = False) -> Optional[str]:\n",
    "        \"\"\"Enhanced process with Claude API supporting translations and multiple output formats\"\"\"\n",
    "        api_key = self.api_key_entry.get() or self.api_key\n",
    "        \n",
    "        try:\n",
    "            self.after(0, lambda: self.update_status(\"Calling Claude API...\"))\n",
    "            self.after(0, lambda: self.progress_bar.set(0.7))\n",
    "            \n",
    "            client = Anthropic(api_key=api_key)\n",
    "            \n",
    "            # Check if this is a translation and if target language requires special handling\n",
    "            target_language = None\n",
    "            if is_translation and hasattr(self, 'target_language_var'):\n",
    "                target_language = self.target_language_var.get()\n",
    "            \n",
    "            # Add instructions for math formatting if LaTeX output is selected\n",
    "            if self.output_format.get() == \"LaTeX PDF\":\n",
    "                if target_language:\n",
    "                    prompt += f\"\\n\\nIMPORTANT: Format all mathematical equations using proper LaTeX syntax. Use equation environments for display equations and inline math mode for inline expressions. Ensure all special symbols are properly escaped. Include appropriate language packages for {target_language}.\"\n",
    "                else:\n",
    "                    prompt += \"\\n\\nIMPORTANT: Format all mathematical equations using proper LaTeX syntax. Use equation environments for display equations and inline math mode for inline expressions. Ensure all special symbols are properly escaped.\"\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=4000,\n",
    "                temperature=0.3,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            result_text = response.content[0].text\n",
    "            \n",
    "            # Handle LaTeX PDF output if selected\n",
    "            if self.output_format.get() == \"LaTeX PDF\":\n",
    "                if target_language:\n",
    "                    result_text = self.ensure_latex_format_multilingual(result_text, target_language)\n",
    "                else:\n",
    "                    result_text = self.ensure_latex_format(result_text)\n",
    "            \n",
    "            self.after(0, lambda: self.progress_bar.set(1.0))\n",
    "            return result_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_queue.put((\"Claude API Error\", f\"Failed to process: {str(e)}\"))\n",
    "            return None\n",
    "    \n",
    "    def ensure_latex_format(self, text: str) -> str:\n",
    "        \"\"\"Ensure text is in proper LaTeX format with beautiful math rendering\"\"\"\n",
    "        \n",
    "        # Clean up problematic characters\n",
    "        text = text.replace('\\u2019', \"'\")\n",
    "        text = text.replace('\\u201c', '``')\n",
    "        text = text.replace('\\u201d', \"''\")\n",
    "        text = text.replace('\\u2013', '--')\n",
    "        text = text.replace('\\u2014', '---')\n",
    "        \n",
    "        # Convert markdown-style math to LaTeX if present\n",
    "        import re\n",
    "        \n",
    "        # Convert inline code blocks with math to LaTeX math mode\n",
    "        text = re.sub(r'```\\n?(.*?)\\n?```', r'\\\\[\\n\\1\\n\\\\]', text, flags=re.DOTALL)\n",
    "        text = re.sub(r'`([^`]+)`', r'$\\1$', text)\n",
    "        \n",
    "        # Convert markdown headers to LaTeX sections\n",
    "        text = re.sub(r'^### (.*?)$', r'\\\\subsection{\\1}', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'^## (.*?)$', r'\\\\section{\\1}', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'^# (.*?)$', r'\\\\chapter{\\1}', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Convert numbered items to subsections\n",
    "        text = re.sub(r'^(\\d+)\\.\\s*([A-Z].*?)$', r'\\\\subsection*{\\\\textbf{\\1. \\2}}', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Convert bullet points\n",
    "        text = re.sub(r'^- (.*?)$', r'\\\\item \\1', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Handle \"Where:\" sections\n",
    "        if 'Where:' in text:\n",
    "            lines = text.split('\\n')\n",
    "            new_lines = []\n",
    "            in_where = False\n",
    "            \n",
    "            for line in lines:\n",
    "                if 'Where:' in line:\n",
    "                    new_lines.append(line.replace('Where:', '\\\\textbf{Where:}'))\n",
    "                    new_lines.append('\\\\begin{itemize}')\n",
    "                    in_where = True\n",
    "                elif in_where and line.strip() and not line.strip().startswith('\\\\item'):\n",
    "                    if line.strip().startswith('-'):\n",
    "                        new_lines.append(line)\n",
    "                    elif re.match(r'^\\d+\\.', line.strip()) or line.strip().startswith('\\\\'):\n",
    "                        new_lines.append('\\\\end{itemize}')\n",
    "                        new_lines.append(line)\n",
    "                        in_where = False\n",
    "                    else:\n",
    "                        new_lines.append(line)\n",
    "                else:\n",
    "                    new_lines.append(line)\n",
    "            \n",
    "            if in_where:\n",
    "                new_lines.append('\\\\end{itemize}')\n",
    "            \n",
    "            text = '\\n'.join(new_lines)\n",
    "        \n",
    "        # Process mathematical equations\n",
    "        def format_equations(text):\n",
    "            \"\"\"Format equations for proper LaTeX display\"\"\"\n",
    "            lines = text.split('\\n')\n",
    "            formatted_lines = []\n",
    "            \n",
    "            for line in lines:\n",
    "                # Check if line contains an equation pattern\n",
    "                if '=' in line and any(char in line for char in ['(', ')', '²', '·', 'Σ', '∂', 'φ', 'τ', 'ε']):\n",
    "                    equation = line.strip()\n",
    "                    \n",
    "                    # Replace special characters with LaTeX commands\n",
    "                    replacements = [\n",
    "                        ('²', '^2'),\n",
    "                        ('·', ' \\\\cdot '),\n",
    "                        ('Σ', '\\\\sum'),\n",
    "                        ('∂', '\\\\partial'),\n",
    "                        ('φ', '\\\\phi'),\n",
    "                        ('Δφ', '\\\\Delta\\\\phi'),\n",
    "                        ('τ', '\\\\tau'),\n",
    "                        ('ε', '\\\\varepsilon'),\n",
    "                        ('σ', '\\\\sigma'),\n",
    "                        ('→', '\\\\rightarrow'),\n",
    "                        ('√', '\\\\sqrt'),\n",
    "                    ]\n",
    "                    \n",
    "                    for old, new in replacements:\n",
    "                        equation = equation.replace(old, new)\n",
    "                    \n",
    "                    # Format simple fractions\n",
    "                    equation = re.sub(r'(\\w+)\\s*/\\s*(\\w+)', r'\\\\frac{\\1}{\\2}', equation)\n",
    "                    \n",
    "                    # Wrap in equation environment if not already wrapped\n",
    "                    if not equation.startswith('\\\\[') and not equation.startswith('$$'):\n",
    "                        formatted_lines.append('\\\\begin{equation}')\n",
    "                        formatted_lines.append(equation)\n",
    "                        formatted_lines.append('\\\\end{equation}')\n",
    "                    else:\n",
    "                        formatted_lines.append(equation)\n",
    "                else:\n",
    "                    formatted_lines.append(line)\n",
    "            \n",
    "            return '\\n'.join(formatted_lines)\n",
    "        \n",
    "        # Apply equation formatting\n",
    "        text = format_equations(text)\n",
    "        \n",
    "        if not text.startswith(\"\\\\documentclass\"):\n",
    "            # Create a complete LaTeX document\n",
    "            latex_text = r\"\"\"\\documentclass[11pt]{article}\n",
    "    \\usepackage[utf8]{inputenc}\n",
    "    \\usepackage[T1]{fontenc}\n",
    "    \\usepackage{lmodern}\n",
    "    \\usepackage{amsmath}\n",
    "    \\usepackage{amssymb}\n",
    "    \\usepackage{amsfonts}\n",
    "    \\usepackage{amsthm}\n",
    "    \\usepackage{mathtools}\n",
    "    \\usepackage{geometry}\n",
    "    \\usepackage{enumitem}\n",
    "    \\usepackage{hyperref}\n",
    "    \\geometry{a4paper, margin=1in}\n",
    "    \n",
    "    \\title{Audio Transcription Analysis}\n",
    "    \\author{Generated Analysis}\n",
    "    \\date{\\today}\n",
    "    \n",
    "    \\begin{document}\n",
    "    \\maketitle\n",
    "    \n",
    "    \"\"\" + text + r\"\"\"\n",
    "    \n",
    "    \\end{document}\"\"\"\n",
    "            return latex_text\n",
    "        else:\n",
    "            # Document already has structure\n",
    "            if \"\\\\usepackage{amsmath}\" not in text:\n",
    "                lines = text.split('\\n')\n",
    "                for i, line in enumerate(lines):\n",
    "                    if line.startswith(\"\\\\documentclass\"):\n",
    "                        math_packages = [\n",
    "                            \"\\\\usepackage[utf8]{inputenc}\",\n",
    "                            \"\\\\usepackage[T1]{fontenc}\",\n",
    "                            \"\\\\usepackage{amsmath}\",\n",
    "                            \"\\\\usepackage{amssymb}\",\n",
    "                            \"\\\\usepackage{amsfonts}\",\n",
    "                        ]\n",
    "                        for j, pkg in enumerate(math_packages):\n",
    "                            if pkg not in text:\n",
    "                                lines.insert(i + 1 + j, pkg)\n",
    "                        break\n",
    "                text = '\\n'.join(lines)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def clean_text_for_export_enhanced(self, text: str, language: str = None) -> str:\n",
    "        \"\"\"Enhanced text cleaning for export with language-specific handling\"\"\"\n",
    "        # Basic cleaning for all languages\n",
    "        replacements = [\n",
    "            ('\\u200b', ''),  # Zero-width space\n",
    "            ('\\ufeff', ''),  # Zero-width no-break space\n",
    "        ]\n",
    "        \n",
    "        # Language-specific cleaning\n",
    "        if language and \"Chinese\" not in language and \"Japanese\" not in language and \"Korean\" not in language:\n",
    "            # Only clean these for non-CJK languages\n",
    "            replacements.extend([\n",
    "                ('\\u2019', \"'\"),\n",
    "                ('\\u201c', '\"'),\n",
    "                ('\\u201d', '\"'),\n",
    "                ('\\u2013', '-'),\n",
    "                ('\\u2014', '--'),\n",
    "                ('\\u2026', '...'),\n",
    "                ('\\u00a0', ' '),\n",
    "            ])\n",
    "        \n",
    "        for old, new in replacements:\n",
    "            text = text.replace(old, new)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def get_encoding_for_language(self, language: str) -> str:\n",
    "        \"\"\"Get appropriate encoding for different languages\"\"\"\n",
    "        if not language:\n",
    "            return 'utf-8'\n",
    "        \n",
    "        encoding_map = {\n",
    "            \"Chinese (Simplified)\": \"utf-8\",\n",
    "            \"Chinese (Traditional)\": \"utf-8\",\n",
    "            \"Japanese\": \"utf-8\",\n",
    "            \"Korean\": \"utf-8\",\n",
    "            \"Arabic\": \"utf-8\",\n",
    "            \"Hebrew\": \"utf-8\",\n",
    "            \"Russian\": \"utf-8\",\n",
    "            \"Greek\": \"utf-8\",\n",
    "            \"Thai\": \"utf-8\",\n",
    "            \"Hindi\": \"utf-8\",\n",
    "            \"Bengali\": \"utf-8\"\n",
    "        }\n",
    "        \n",
    "        return encoding_map.get(language, 'utf-8')\n",
    "    \n",
    "    def export_text_enhanced(self, text_type: str):\n",
    "        \"\"\"Enhanced export function supporting multiple languages and formats\"\"\"\n",
    "        if text_type == \"transcription\" and not self.transcribed_text:\n",
    "            messagebox.showwarning(\"No Content\", \"No transcription to export\")\n",
    "            return\n",
    "        elif text_type == \"result\" and (self.current_history_index < 0 or not self.process_history):\n",
    "            messagebox.showwarning(\"No Content\", \"No processed result to export\")\n",
    "            return\n",
    "        \n",
    "        output_format = self.output_format.get()\n",
    "        \n",
    "        # Check if content is a translation\n",
    "        is_translation = False\n",
    "        target_language = None\n",
    "        if text_type == \"result\" and self.current_history_index >= 0:\n",
    "            _, content = self.process_history[self.current_history_index]\n",
    "            if content.startswith(\"[Translation to\"):\n",
    "                is_translation = True\n",
    "                # Extract language from header\n",
    "                import re\n",
    "                match = re.search(r'\\[Translation to (.+?)\\]', content)\n",
    "                if match:\n",
    "                    target_language = match.group(1)\n",
    "        \n",
    "        if output_format == \"LaTeX PDF\":\n",
    "            # For LaTeX PDF, we need to compile to PDF with language support\n",
    "            self.export_as_latex_pdf_enhanced(text_type, target_language)\n",
    "        else:\n",
    "            # Regular text export with proper encoding for different languages\n",
    "            default_ext = self.get_default_extension()\n",
    "            \n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                defaultextension=default_ext,\n",
    "                filetypes=[\n",
    "                    (\"Text Files\", \"*.txt\"),\n",
    "                    (\"Markdown Files\", \"*.md\"),\n",
    "                    (\"JSON Files\", \"*.json\"),\n",
    "                    (\"LaTeX Files\", \"*.tex\"),\n",
    "                    (\"All Files\", \"*.*\")\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            if file_path:\n",
    "                if text_type == \"transcription\":\n",
    "                    content = self.transcribed_text\n",
    "                else:\n",
    "                    _, content = self.process_history[self.current_history_index]\n",
    "                \n",
    "                try:\n",
    "                    # Determine encoding based on language\n",
    "                    encoding = self.get_encoding_for_language(target_language)\n",
    "                    \n",
    "                    # Use appropriate encoding with error handling\n",
    "                    with open(file_path, 'w', encoding=encoding, errors='replace') as f:\n",
    "                        # Clean problematic characters before saving\n",
    "                        content = self.clean_text_for_export_enhanced(content, target_language)\n",
    "                        f.write(content)\n",
    "                    messagebox.showinfo(\"Export Success\", f\"File saved successfully\")\n",
    "                except Exception as e:\n",
    "                    # Fallback to UTF-8 with BOM for better compatibility\n",
    "                    try:\n",
    "                        with open(file_path, 'w', encoding='utf-8-sig', errors='replace') as f:\n",
    "                            f.write(content)\n",
    "                        messagebox.showinfo(\"Export Success\", f\"File saved successfully (UTF-8 with BOM)\")\n",
    "                    except Exception as e2:\n",
    "                        messagebox.showerror(\"Export Error\", f\"Failed to save file: {str(e2)}\")\n",
    "    \n",
    "    def get_default_extension(self) -> str:\n",
    "        \"\"\"Get default file extension based on output format\"\"\"\n",
    "        format_map = {\n",
    "            \"Markdown\": \".md\",\n",
    "            \"Plain Text\": \".txt\",\n",
    "            \"JSON\": \".json\",\n",
    "            \"Bullet Points\": \".txt\",\n",
    "            \"LaTeX PDF\": \".tex\"\n",
    "        }\n",
    "        return format_map.get(self.output_format.get(), \".txt\")\n",
    "    \n",
    "    def export_as_latex_pdf_enhanced(self, text_type: str, target_language: str = None):\n",
    "        \"\"\"Enhanced LaTeX PDF export with multi-language support\"\"\"\n",
    "        if text_type == \"transcription\":\n",
    "            if not self.transcribed_text:\n",
    "                messagebox.showwarning(\"No Content\", \"No transcription to export\")\n",
    "                return\n",
    "            content = self.transcribed_text\n",
    "        else:\n",
    "            if self.current_history_index < 0 or not self.process_history:\n",
    "                messagebox.showwarning(\"No Content\", \"No processed result to export\")\n",
    "                return\n",
    "            _, content = self.process_history[self.current_history_index]\n",
    "        \n",
    "        # Ensure content is in LaTeX format with language support\n",
    "        if target_language:\n",
    "            latex_content = self.ensure_latex_format_multilingual(content, target_language)\n",
    "        else:\n",
    "            latex_content = self.ensure_latex_format(content)\n",
    "        \n",
    "        # Ask user where to save PDF\n",
    "        pdf_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".pdf\",\n",
    "            filetypes=[(\"PDF Files\", \"*.pdf\"), (\"All Files\", \"*.*\")]\n",
    "        )\n",
    "        \n",
    "        if not pdf_path:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Create temporary directory for LaTeX compilation\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                tex_file = Path(temp_dir) / \"document.tex\"\n",
    "                \n",
    "                # Write LaTeX content with proper encoding handling\n",
    "                encoding = 'utf-8' if not target_language else self.get_encoding_for_language(target_language)\n",
    "                with open(tex_file, 'w', encoding=encoding, errors='replace') as f:\n",
    "                    f.write(latex_content)\n",
    "                \n",
    "                # Try to compile with pdflatex or xelatex for better Unicode support\n",
    "                try:\n",
    "                    # Try different possible paths for LaTeX compilers\n",
    "                    latex_compilers = [\n",
    "                        (\"xelatex\", [\"/usr/local/texlive/2025/bin/universal-darwin/xelatex\",\n",
    "                                    \"/usr/local/texlive/2024/bin/universal-darwin/xelatex\",\n",
    "                                    \"/Library/TeX/texbin/xelatex\",\n",
    "                                    \"xelatex\"]),\n",
    "                        (\"pdflatex\", [\"/usr/local/texlive/2025/bin/universal-darwin/pdflatex\",\n",
    "                                     \"/usr/local/texlive/2024/bin/universal-darwin/pdflatex\",\n",
    "                                     \"/Library/TeX/texbin/pdflatex\",\n",
    "                                     \"pdflatex\"])\n",
    "                    ]\n",
    "                    \n",
    "                    compiler_cmd = None\n",
    "                    compiler_name = None\n",
    "                    \n",
    "                    # Prefer XeLaTeX for better Unicode support\n",
    "                    if target_language in [\"Chinese (Simplified)\", \"Chinese (Traditional)\", \n",
    "                                          \"Japanese\", \"Korean\", \"Arabic\", \"Hebrew\"]:\n",
    "                        latex_compilers.reverse()  # Try XeLaTeX first for these languages\n",
    "                    \n",
    "                    for name, paths in latex_compilers:\n",
    "                        for path in paths:\n",
    "                            if os.path.exists(path) or path in [\"xelatex\", \"pdflatex\"]:\n",
    "                                try:\n",
    "                                    subprocess.run([path, \"--version\"], capture_output=True, timeout=2)\n",
    "                                    compiler_cmd = path\n",
    "                                    compiler_name = name\n",
    "                                    break\n",
    "                                except:\n",
    "                                    continue\n",
    "                        if compiler_cmd:\n",
    "                            break\n",
    "                    \n",
    "                    if not compiler_cmd:\n",
    "                        raise FileNotFoundError(\"No LaTeX compiler found\")\n",
    "                    \n",
    "                    # Run LaTeX compiler with proper encoding\n",
    "                    env = os.environ.copy()\n",
    "                    env['LANG'] = 'en_US.UTF-8'\n",
    "                    \n",
    "                    for _ in range(2):\n",
    "                        result = subprocess.run(\n",
    "                            [compiler_cmd, \"-interaction=nonstopmode\", \"-output-directory\", temp_dir, str(tex_file)],\n",
    "                            capture_output=True,\n",
    "                            text=True,\n",
    "                            timeout=30,\n",
    "                            env=env,\n",
    "                            encoding='utf-8',\n",
    "                            errors='replace'\n",
    "                        )\n",
    "                    \n",
    "                    # Check if PDF was created\n",
    "                    pdf_file = Path(temp_dir) / \"document.pdf\"\n",
    "                    if pdf_file.exists():\n",
    "                        # Copy to destination\n",
    "                        import shutil\n",
    "                        shutil.copy(pdf_file, pdf_path)\n",
    "                        messagebox.showinfo(\"Export Success\", f\"PDF exported successfully using {compiler_name}\")\n",
    "                    else:\n",
    "                        raise Exception(\"PDF file was not generated\")\n",
    "                            \n",
    "                except FileNotFoundError:\n",
    "                    # LaTeX not installed or not found\n",
    "                    messagebox.showerror(\n",
    "                        \"LaTeX Not Found\",\n",
    "                        \"LaTeX compiler could not be found.\\n\\n\"\n",
    "                        \"Please install MacTeX or TeX Live.\\n\"\n",
    "                        \"For better Unicode support, XeLaTeX is recommended.\\n\\n\"\n",
    "                        \"Alternatively, you can export as .tex and compile manually.\"\n",
    "                    )\n",
    "                    \n",
    "                    # Offer to save as .tex instead\n",
    "                    if messagebox.askyesno(\"Save as LaTeX\", \"Would you like to save as a .tex file instead?\"):\n",
    "                        tex_path = pdf_path.replace('.pdf', '.tex')\n",
    "                        with open(tex_path, 'w', encoding='utf-8', errors='replace') as f:\n",
    "                            f.write(latex_content)\n",
    "                        messagebox.showinfo(\"Export Success\", f\"LaTeX file saved to {tex_path}\")\n",
    "                            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Export Error\", f\"Failed to export PDF: {str(e)}\")\n",
    "\n",
    "    def clean_transcribed_text(self):\n",
    "        \"\"\"Clean transcribed text using Claude API\"\"\"\n",
    "        if not self.transcribed_text:\n",
    "            messagebox.showwarning(\"No Content\", \"No transcription to clean\")\n",
    "            return\n",
    "        \n",
    "        api_key = self.api_key_entry.get() or self.api_key\n",
    "        if not api_key:\n",
    "            messagebox.showwarning(\"API Key Required\", \"Please enter your Anthropic API key\")\n",
    "            return\n",
    "        \n",
    "        def clean():\n",
    "            try:\n",
    "                self.after(0, lambda: self.clean_button.configure(state=\"disabled\"))\n",
    "                self.after(0, lambda: self.update_status(\"Cleaning transcription...\"))\n",
    "                self.after(0, lambda: self.progress_bar.set(0.5))\n",
    "                \n",
    "                client = Anthropic(api_key=api_key)\n",
    "                \n",
    "                prompt = f\"\"\"Clean the following transcribed text by:\n",
    "    1. Correcting any obvious transcription errors or strange words\n",
    "    2. Fixing grammar and punctuation while preserving the original meaning\n",
    "    3. Removing filler words (um, uh, etc.) where appropriate\n",
    "    4. Making the text flow naturally as written prose\n",
    "    5. DO NOT summarize or remove content - just clean and correct\n",
    "    \n",
    "    Return ONLY the cleaned text without any commentary or explanations.\n",
    "    \n",
    "    Text to clean:\n",
    "    {self.transcribed_text}\"\"\"\n",
    "                \n",
    "                response = client.messages.create(\n",
    "                    model=\"claude-sonnet-4-20250514\",\n",
    "                    max_tokens=4000,\n",
    "                    temperature=0.2,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                \n",
    "                cleaned_text = response.content[0].text\n",
    "                \n",
    "                # Update transcription with cleaned text\n",
    "                self.after(0, lambda: self.update_transcription_result(cleaned_text))\n",
    "                self.after(0, lambda: self.trans_status.configure(\n",
    "                    text=\"Transcription cleaned\", \n",
    "                    text_color=(\"blue\", \"lightblue\")\n",
    "                ))\n",
    "                self.after(0, lambda: self.update_status(\"Transcription cleaned successfully\"))\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Cleaning Error\", f\"Failed to clean text: {str(e)}\"))\n",
    "            finally:\n",
    "                self.after(0, lambda: self.progress_bar.set(0))\n",
    "                self.after(0, lambda: self.clean_button.configure(state=\"normal\"))\n",
    "        \n",
    "        threading.Thread(target=clean, daemon=True).start()\n",
    "    \n",
    "    # Function to save network plot\n",
    "    def save_network_plot(self, source_path):\n",
    "        \"\"\"Save network plot to user-specified location\"\"\"\n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".png\",\n",
    "            filetypes=[\n",
    "                (\"PNG Files\", \"*.png\"),\n",
    "                (\"All Files\", \"*.*\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if file_path:\n",
    "            import shutil\n",
    "            try:\n",
    "                shutil.copy(source_path, file_path)\n",
    "                messagebox.showinfo(\"Save Success\", \"Network plot saved successfully\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Save Error\", f\"Failed to save plot: {str(e)}\")\n",
    "    \n",
    "    def toggle_recording(self):\n",
    "        \"\"\"Start or stop audio recording\"\"\"\n",
    "        if not self.is_recording:\n",
    "            self.start_recording()\n",
    "        else:\n",
    "            self.stop_recording()\n",
    "    \n",
    "    def start_recording(self):\n",
    "        \"\"\"Start recording audio from microphone with fallback options\"\"\"\n",
    "        try:\n",
    "            # First try with sounddevice (preferred method)\n",
    "            try:\n",
    "                import sounddevice as sd\n",
    "                devices = sd.query_devices()\n",
    "                input_device = sd.default.device[0]\n",
    "                \n",
    "                if input_device is None:\n",
    "                    raise Exception(\"No microphone detected with sounddevice\")\n",
    "                \n",
    "                # Use sounddevice method\n",
    "                self._start_recording_sounddevice()\n",
    "                return\n",
    "                \n",
    "            except (ImportError, Exception) as e:\n",
    "                print(f\"Sounddevice not available: {e}\")\n",
    "                \n",
    "                # Fallback to pyaudio if sounddevice fails\n",
    "                try:\n",
    "                    import pyaudio\n",
    "                    self._start_recording_pyaudio()\n",
    "                    return\n",
    "                except ImportError:\n",
    "                    pass\n",
    "                \n",
    "                # Final fallback: use system command (macOS/Linux)\n",
    "                if sys.platform in ['darwin', 'linux']:\n",
    "                    self._start_recording_system()\n",
    "                else:\n",
    "                    messagebox.showerror(\n",
    "                        \"Recording Error\", \n",
    "                        \"Audio recording requires sounddevice or pyaudio.\\n\"\n",
    "                        \"Please install: pip install sounddevice\\n\"\n",
    "                        \"If that fails, try: pip install pyaudio\"\n",
    "                    )\n",
    "                    \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Recording Error\", f\"Failed to start recording: {str(e)}\")\n",
    "            self.is_recording = False\n",
    "    \n",
    "    def _start_recording_sounddevice(self):\n",
    "        \"\"\"Recording with sounddevice (original method)\"\"\"\n",
    "        import sounddevice as sd\n",
    "        \n",
    "        self.is_recording = True\n",
    "        self.recording_data = []\n",
    "        self.recording_start_time = time.time()\n",
    "        \n",
    "        # Update UI\n",
    "        self.record_button.configure(\n",
    "            text=\"⏹️ Stop Recording\",\n",
    "            fg_color=(\"red\", \"darkred\")\n",
    "        )\n",
    "        self.recording_status.configure(text=\"Recording...\")\n",
    "        self.use_recording_button.configure(state=\"disabled\")\n",
    "        \n",
    "        # Start recording in background thread\n",
    "        def record_audio():\n",
    "            try:\n",
    "                with sd.InputStream(\n",
    "                    samplerate=self.recording_samplerate,\n",
    "                    channels=1,\n",
    "                    callback=self.audio_callback\n",
    "                ):\n",
    "                    while self.is_recording:\n",
    "                        time.sleep(0.1)\n",
    "                        # Update timer on main thread\n",
    "                        elapsed = time.time() - self.recording_start_time\n",
    "                        mins, secs = divmod(int(elapsed), 60)\n",
    "                        self.after(0, lambda: self.recording_timer.configure(\n",
    "                            text=f\"⏱️ {mins:02d}:{secs:02d}\"\n",
    "                        ))\n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Recording Error\", str(e)))\n",
    "                self.after(0, self.stop_recording)\n",
    "        \n",
    "        self.recording_thread = threading.Thread(target=record_audio, daemon=True)\n",
    "        self.recording_thread.start()\n",
    "    \n",
    "    def _start_recording_pyaudio(self):\n",
    "        \"\"\"Fallback recording with pyaudio\"\"\"\n",
    "        import pyaudio\n",
    "        \n",
    "        self.is_recording = True\n",
    "        self.recording_data = []\n",
    "        self.recording_start_time = time.time()\n",
    "        \n",
    "        # Update UI\n",
    "        self.record_button.configure(\n",
    "            text=\"⏹️ Stop Recording\",\n",
    "            fg_color=(\"red\", \"darkred\")\n",
    "        )\n",
    "        self.recording_status.configure(text=\"Recording (pyaudio)...\")\n",
    "        self.use_recording_button.configure(state=\"disabled\")\n",
    "        \n",
    "        def record_audio():\n",
    "            try:\n",
    "                p = pyaudio.PyAudio()\n",
    "                \n",
    "                stream = p.open(\n",
    "                    format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=self.recording_samplerate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=1024\n",
    "                )\n",
    "                \n",
    "                while self.is_recording:\n",
    "                    data = stream.read(1024, exception_on_overflow=False)\n",
    "                    audio_array = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "                    self.recording_data.append(audio_array.reshape(-1, 1))\n",
    "                    \n",
    "                    # Update timer\n",
    "                    elapsed = time.time() - self.recording_start_time\n",
    "                    mins, secs = divmod(int(elapsed), 60)\n",
    "                    self.after(0, lambda: self.recording_timer.configure(\n",
    "                        text=f\"⏱️ {mins:02d}:{secs:02d}\"\n",
    "                    ))\n",
    "                \n",
    "                stream.stop_stream()\n",
    "                stream.close()\n",
    "                p.terminate()\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Recording Error\", str(e)))\n",
    "                self.after(0, self.stop_recording)\n",
    "        \n",
    "        self.recording_thread = threading.Thread(target=record_audio, daemon=True)\n",
    "        self.recording_thread.start()\n",
    "    \n",
    "    def _start_recording_system(self):\n",
    "        \"\"\"System command fallback for macOS/Linux\"\"\"\n",
    "        self.is_recording = True\n",
    "        self.recording_start_time = time.time()\n",
    "        \n",
    "        # Create temporary file for recording\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        recordings_dir = Path(\"recordings\")\n",
    "        recordings_dir.mkdir(exist_ok=True)\n",
    "        self.recorded_file_path = recordings_dir / f\"recording_{timestamp}.wav\"\n",
    "        \n",
    "        # Update UI\n",
    "        self.record_button.configure(\n",
    "            text=\"⏹️ Stop Recording\",\n",
    "            fg_color=(\"red\", \"darkred\")\n",
    "        )\n",
    "        self.recording_status.configure(text=\"Recording (system)...\")\n",
    "        self.use_recording_button.configure(state=\"disabled\")\n",
    "        \n",
    "        def record_audio():\n",
    "            try:\n",
    "                if sys.platform == 'darwin':  # macOS\n",
    "                    # Use sox or ffmpeg if available\n",
    "                    cmd = [\n",
    "                        'ffmpeg', '-f', 'avfoundation', '-i', ':0',\n",
    "                        '-t', '3600',  # Max 1 hour\n",
    "                        '-ar', str(self.recording_samplerate),\n",
    "                        '-ac', '1',\n",
    "                        str(self.recorded_file_path)\n",
    "                    ]\n",
    "                else:  # Linux\n",
    "                    cmd = [\n",
    "                        'arecord', '-f', 'cd', '-t', 'wav',\n",
    "                        '-d', '3600',  # Max 1 hour\n",
    "                        str(self.recorded_file_path)\n",
    "                    ]\n",
    "                \n",
    "                self.recording_process = subprocess.Popen(\n",
    "                    cmd,\n",
    "                    stdout=subprocess.PIPE,\n",
    "                    stderr=subprocess.PIPE\n",
    "                )\n",
    "                \n",
    "                # Update timer while recording\n",
    "                while self.is_recording and self.recording_process.poll() is None:\n",
    "                    time.sleep(0.1)\n",
    "                    elapsed = time.time() - self.recording_start_time\n",
    "                    mins, secs = divmod(int(elapsed), 60)\n",
    "                    self.after(0, lambda: self.recording_timer.configure(\n",
    "                        text=f\"⏱️ {mins:02d}:{secs:02d}\"\n",
    "                    ))\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.error_queue.put((\"Recording Error\", str(e)))\n",
    "                self.after(0, self.stop_recording)\n",
    "        \n",
    "        self.recording_thread = threading.Thread(target=record_audio, daemon=True)\n",
    "        self.recording_thread.start()\n",
    "    \n",
    "    def audio_callback(self, indata, frames, time_info, status):\n",
    "        \"\"\"Callback for audio recording\"\"\"\n",
    "        if status:\n",
    "            print(f\"Recording status: {status}\")\n",
    "        self.recording_data.append(indata.copy())\n",
    "    \n",
    "    def stop_recording(self):\n",
    "        \"\"\"Stop recording and save audio file\"\"\"\n",
    "        if not self.is_recording:\n",
    "            return\n",
    "        \n",
    "        self.is_recording = False\n",
    "        \n",
    "        # Update UI\n",
    "        self.record_button.configure(\n",
    "            text=\"🎤 Start Recording\",\n",
    "            fg_color=(\"gray75\", \"gray25\")\n",
    "        )\n",
    "        self.recording_status.configure(text=\"Processing recording...\")\n",
    "        self.recording_timer.configure(text=\"\")\n",
    "        \n",
    "        # Stop system recording if using that method\n",
    "        if hasattr(self, 'recording_process') and self.recording_process is not None:\n",
    "            try:\n",
    "                self.recording_process.terminate()\n",
    "                self.recording_process.wait(timeout=2)\n",
    "            except:\n",
    "                try:\n",
    "                    self.recording_process.kill()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # For system recording, file is already saved\n",
    "            if self.recorded_file_path and self.recorded_file_path.exists():\n",
    "                file_size = self.recorded_file_path.stat().st_size\n",
    "                if file_size > 0:\n",
    "                    self.recording_status.configure(\n",
    "                        text=f\"Saved: {self.recorded_file_path.name}\"\n",
    "                    )\n",
    "                    self.use_recording_button.configure(state=\"normal\")\n",
    "                    self.update_status(f\"Recording saved: {self.recorded_file_path.name}\")\n",
    "                else:\n",
    "                    self.recording_status.configure(text=\"Recording failed - empty file\")\n",
    "            \n",
    "            # Clean up\n",
    "            self.recording_process = None\n",
    "            return\n",
    "        \n",
    "        # Wait for recording thread to finish (for sounddevice/pyaudio methods)\n",
    "        if hasattr(self, 'recording_thread') and self.recording_thread:\n",
    "            self.recording_thread.join(timeout=1)\n",
    "        \n",
    "        # Save recording for sounddevice/pyaudio methods\n",
    "        if self.recording_data:\n",
    "            try:\n",
    "                # Combine all audio chunks\n",
    "                audio_data = np.concatenate(self.recording_data, axis=0)\n",
    "                \n",
    "                # Create filename with timestamp\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"recording_{timestamp}.wav\"\n",
    "                \n",
    "                # Create recordings directory if it doesn't exist\n",
    "                recordings_dir = Path(\"recordings\")\n",
    "                recordings_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                # Save audio file\n",
    "                self.recorded_file_path = recordings_dir / filename\n",
    "                \n",
    "                # Try to save with soundfile, fall back to scipy if needed\n",
    "                try:\n",
    "                    import soundfile as sf\n",
    "                    sf.write(\n",
    "                        self.recorded_file_path,\n",
    "                        audio_data,\n",
    "                        self.recording_samplerate\n",
    "                    )\n",
    "                except ImportError:\n",
    "                    try:\n",
    "                        # Fallback to scipy\n",
    "                        from scipy.io import wavfile\n",
    "                        # Convert float32 to int16 for scipy\n",
    "                        audio_int16 = (audio_data * 32767).astype(np.int16)\n",
    "                        wavfile.write(\n",
    "                            self.recorded_file_path,\n",
    "                            self.recording_samplerate,\n",
    "                            audio_int16\n",
    "                        )\n",
    "                    except ImportError:\n",
    "                        # Final fallback: save as numpy array and convert later\n",
    "                        np.save(str(self.recorded_file_path).replace('.wav', '.npy'), audio_data)\n",
    "                        messagebox.showwarning(\n",
    "                            \"Format Notice\", \n",
    "                            \"Recording saved as .npy file. Install soundfile or scipy to save as .wav\"\n",
    "                        )\n",
    "                        filename = filename.replace('.wav', '.npy')\n",
    "                        self.recorded_file_path = recordings_dir / filename\n",
    "                \n",
    "                # Update UI\n",
    "                duration = len(audio_data) / self.recording_samplerate\n",
    "                mins, secs = divmod(int(duration), 60)\n",
    "                self.recording_status.configure(\n",
    "                    text=f\"Saved: {filename} ({mins:02d}:{secs:02d})\"\n",
    "                )\n",
    "                self.use_recording_button.configure(state=\"normal\")\n",
    "                self.update_status(f\"Recording saved: {filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Save Error\", f\"Failed to save recording: {str(e)}\")\n",
    "                self.recording_status.configure(text=\"Failed to save recording\")\n",
    "        else:\n",
    "            self.recording_status.configure(text=\"No audio recorded\")\n",
    "        \n",
    "        # Clean up\n",
    "        self.recording_data = []\n",
    "        self.recording_thread = None\n",
    "    \n",
    "    def use_recording(self):\n",
    "        \"\"\"Use the last recording as input file\"\"\"\n",
    "        if self.recorded_file_path and self.recorded_file_path.exists():\n",
    "            self.audio_file_path = str(self.recorded_file_path)\n",
    "            filename = os.path.basename(self.audio_file_path)\n",
    "            self.file_label.configure(text=f\"Selected: {filename}\")\n",
    "            \n",
    "            # Update valid range for the recording\n",
    "            self.update_valid_range()\n",
    "            \n",
    "            # Reset transcription when new recording is used\n",
    "            self.transcribed_text = \"\"\n",
    "            self.trans_text.delete(\"1.0\", \"end\")\n",
    "            self.trans_word_count.configure(text=\"Words: 0 | Characters: 0\")\n",
    "            self.trans_status.configure(text=\"Ready to transcribe\", text_color=(\"gray50\", \"gray50\"))\n",
    "            \n",
    "            # Clear visualization panel\n",
    "            if hasattr(self, 'network_display'):\n",
    "                self.network_display.configure(\n",
    "                    text=\"No network generated yet\\n\\nClick 'Generate Network Plot' to visualize\",\n",
    "                    image=None\n",
    "                )\n",
    "                if hasattr(self.network_display, 'image'):\n",
    "                    self.network_display.image = None\n",
    "            \n",
    "            if hasattr(self, 'semantic_summary_text'):\n",
    "                self.semantic_summary_text.configure(state=\"normal\")\n",
    "                self.semantic_summary_text.delete(\"1.0\", \"end\")\n",
    "                self.semantic_summary_text.insert(\"1.0\", \"No summary generated yet.\\n\\nClick 'Generate' to create a semantic summary of the transcribed text.\")\n",
    "                self.semantic_summary_text.configure(state=\"disabled\")\n",
    "            \n",
    "            # Update button states to enable transcribe button\n",
    "            self.update_button_states()\n",
    "            self.update_status(f\"Using recording: {filename}\")\n",
    "            \n",
    "            # Switch to transcription tab\n",
    "            self.tabview.set(\"📝 Transcription\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"No Recording\", \"No recording available to use\")\n",
    "    \n",
    "    def clear_all(self):\n",
    "        \"\"\"Clear all text content (modified to stop recording if active)\"\"\"\n",
    "        # Stop recording if in progress\n",
    "        if self.is_recording:\n",
    "            self.stop_recording()\n",
    "        \n",
    "        # Original clear_all code continues...\n",
    "        if self.transcribed_text or self.process_history:\n",
    "            if messagebox.askyesno(\"Clear All\", \"Clear all content and history?\"):\n",
    "                self.trans_text.delete(\"1.0\", \"end\")\n",
    "                self.result_text.delete(\"1.0\", \"end\")\n",
    "                self.transcribed_text = \"\"\n",
    "                self.process_history = []\n",
    "                self.current_history_index = -1\n",
    "                self.trans_word_count.configure(text=\"Words: 0 | Characters: 0\")\n",
    "                self.trans_status.configure(text=\"No transcription yet\", text_color=(\"gray50\", \"gray50\"))\n",
    "                self.result_status.configure(text=\"No processed result yet\", text_color=(\"gray50\", \"gray50\"))\n",
    "                self.update_history_navigation()\n",
    "                self.update_status(\"Cleared all content\")\n",
    "                self.update_button_states()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    # Check for required packages\n",
    "    required_packages = {\n",
    "        'whisper': 'openai-whisper',\n",
    "        'anthropic': 'anthropic',\n",
    "        'customtkinter': 'customtkinter',\n",
    "        'sounddevice': 'sounddevice',\n",
    "        'soundfile': 'soundfile'\n",
    "    }\n",
    "    \n",
    "    missing_packages = []\n",
    "    for module, package in required_packages.items():\n",
    "        try:\n",
    "            __import__(module)\n",
    "        except ImportError:\n",
    "            missing_packages.append(package)\n",
    "    \n",
    "    if missing_packages:\n",
    "        print(\"Missing required packages. Please install them using:\")\n",
    "        print(f\"pip install {' '.join(missing_packages)}\")\n",
    "        print(\"\\nFor macOS, you may also need:\")\n",
    "        print(\"brew install ffmpeg portaudio\")  # Added portaudio\n",
    "        print(\"\\nFor LaTeX PDF export (optional):\")\n",
    "        print(\"- Windows: Install MiKTeX or TeX Live\")\n",
    "        print(\"- macOS: Install MacTeX\")\n",
    "        print(\"- Linux: sudo apt-get install texlive-full\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Run the application\n",
    "    app = AudioAnalyzerApp()\n",
    "    app.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647ee0d-fb2b-4067-bcdd-080af9706ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
